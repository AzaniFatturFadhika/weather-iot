{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udf24\ufe0f Weather Model Training - Dual Model (Hourly + Daily)\n",
    "\n",
    "Notebook ini mengikuti panduan dari `training_guide.md` untuk melatih **dual-model**:\n",
    "1. **Model Hourly** - Prediksi per-jam (temp, humidity, windspeed, pressure, weather_code)\n",
    "2. **Model Daily** - Prediksi per-hari (temp_min, temp_max, temp_mean, humidity_avg, windspeed_avg, pressure_avg, weather_code_dominant)\n",
    "\n",
    "**Output:** 7 file model `.pkl` untuk berbagai kebutuhan deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Persiapan Lingkungan dan Pemuatan Pustaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies jika belum ada\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn xgboost joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    from xgboost import XGBRegressor, XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Skipping XGBoost models.\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "# Joblib for saving models\n",
    "import joblib\n",
    "\n",
    "print(\"\u2705 Semua pustaka berhasil diimpor!\")\n",
    "print(f\"   - Pandas: {pd.__version__}\")\n",
    "print(f\"   - NumPy: {np.__version__}\")\n",
    "print(f\"   - XGBoost Available: {XGBOOST_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pengumpulan dan Pemuatan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (23 kolom: hourly + daily features)\n",
    "DATA_PATH = '../data/historical_data_2000_2024.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Konversi timestamp ke datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Urutkan berdasarkan waktu (PENTING untuk time-series)\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"\ud83d\udcca Dataset loaded: {len(df):,} baris x {len(df.columns)} kolom\")\n",
    "print(f\"\ud83d\udcc5 Rentang waktu: {df['timestamp'].min()} - {df['timestamp'].max()}\")\n",
    "print(f\"\\n\ud83d\udccb Kolom dataset:\")\n",
    "print(df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info struktur data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analisis Data Eksplorasi (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Statistik Deskriptif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik deskriptif untuk fitur numerik\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualisasi Distribusi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi distribusi parameter cuaca utama (Hourly)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "params = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "titles = ['Temperature (\u00b0C)', 'Humidity (%)', 'Wind Speed (km/h)', 'Sea Level Pressure (hPa)']\n",
    "\n",
    "for ax, param, title in zip(axes.flatten(), params, titles):\n",
    "    sns.histplot(df[param], kde=True, ax=ax, color='steelblue')\n",
    "    ax.set_title(f'Distribusi {title}')\n",
    "    ax.set_xlabel(title)\n",
    "\n",
    "plt.suptitle('Distribusi Parameter Cuaca Hourly', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi distribusi parameter cuaca Daily\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "daily_params = ['temp_max_daily', 'temp_min_daily', 'temp_mean_daily', \n",
    "                'humidity_avg_daily', 'pressure_avg_daily', 'windspeed_avg_daily']\n",
    "titles = ['Temp Max (\u00b0C)', 'Temp Min (\u00b0C)', 'Temp Mean (\u00b0C)', \n",
    "          'Humidity Avg (%)', 'Pressure Avg (hPa)', 'Windspeed Avg (km/h)']\n",
    "\n",
    "for ax, param, title in zip(axes.flatten(), daily_params, titles):\n",
    "    sns.histplot(df[param].dropna(), kde=True, ax=ax, color='coral')\n",
    "    ax.set_title(f'Distribusi {title}')\n",
    "    ax.set_xlabel(title)\n",
    "\n",
    "plt.suptitle('Distribusi Parameter Cuaca Daily', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Analisis Korelasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap korelasi\n",
    "numeric_cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure', 'rain', \n",
    "                'weather_code', 'temp_max_daily', 'temp_min_daily', 'temp_mean_daily',\n",
    "                'humidity_avg_daily', 'pressure_avg_daily', 'windspeed_avg_daily']\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Heatmap Korelasi Antar Variabel Cuaca (Hourly + Daily)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Analisis Korelasi: weather_code dan rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis hubungan weather_code dengan rain\n",
    "weather_rain_analysis = df.groupby('weather_code')[['rain']].agg(['mean', 'min', 'max', 'count'])\n",
    "print(\"\ud83d\udcca Weather Code vs Rain:\")\n",
    "weather_rain_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifikasi korelasi deterministik\n",
    "print(f\"\\n\ud83d\udd0d Verifikasi rain == precipitation: {(df['rain'] == df['precipitation']).all()}\")\n",
    "print(f\"\ud83d\udd0d Weather codes dengan rain > 0: {sorted(df[df['rain'] > 0]['weather_code'].unique())}\")\n",
    "print(f\"\ud83d\udd0d Weather codes dengan rain = 0: {sorted(df[df['rain'] == 0]['weather_code'].unique())}\")\n",
    "\n",
    "# Kesimpulan\n",
    "print(\"\\n\u2705 KESIMPULAN:\")\n",
    "print(\"   - rain dan precipitation IDENTIK di seluruh dataset\")\n",
    "print(\"   - weather_code >= 50 SELALU hujan (deterministik)\")\n",
    "print(\"   - Tidak perlu memprediksi rain terpisah, cukup prediksi weather_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pra-pemrosesan Data dan Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preprocessing Data Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataframe untuk preprocessing\n",
    "df_hourly = df.copy()\n",
    "\n",
    "# 1. Label Encoding untuk 'conditions'\n",
    "le_conditions = LabelEncoder()\n",
    "df_hourly['conditions_encoded'] = le_conditions.fit_transform(df_hourly['conditions'])\n",
    "\n",
    "print(\"\ud83d\udcdd Label Encoding untuk 'conditions':\")\n",
    "for i, label in enumerate(le_conditions.classes_):\n",
    "    print(f\"   {i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Label Encoding untuk 'weather_code' (PENTING untuk XGBoost)\n",
    "# XGBoost membutuhkan label berupa integer berurutan (0, 1, 2, ...)\n",
    "le_weather_code = LabelEncoder()\n",
    "df_hourly['weather_code_encoded'] = le_weather_code.fit_transform(df_hourly['weather_code'])\n",
    "\n",
    "print(\"\ud83d\udcdd Label Encoding untuk 'weather_code':\")\n",
    "for i, label in enumerate(le_weather_code.classes_):\n",
    "    print(f\"   {i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Engineering: Lag Features untuk Hourly\n",
    "hourly_target_cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "\n",
    "for col in hourly_target_cols:\n",
    "    # Lag 1 jam\n",
    "    df_hourly[f'{col}_lag_1'] = df_hourly[col].shift(1)\n",
    "    # Lag 24 jam\n",
    "    df_hourly[f'{col}_lag_24'] = df_hourly[col].shift(24)\n",
    "    # Rolling mean 24 jam\n",
    "    df_hourly[f'{col}_rolling_24'] = df_hourly[col].rolling(window=24).mean()\n",
    "\n",
    "print(f\"\u2705 Feature Engineering Hourly selesai! Kolom baru: {12} fitur lag & rolling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Hapus baris dengan NaN (akibat lag & rolling)\n",
    "rows_before = len(df_hourly)\n",
    "df_hourly = df_hourly.dropna().reset_index(drop=True)\n",
    "rows_after = len(df_hourly)\n",
    "\n",
    "print(f\"\ud83d\uddd1\ufe0f Baris dihapus (NaN): {rows_before - rows_after:,}\")\n",
    "print(f\"\ud83d\udcca Dataset Hourly final: {rows_after:,} baris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Preprocessing Data Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregasi data hourly menjadi daily\n",
    "df_daily = df.groupby(['year', 'month', 'day']).agg({\n",
    "    'temp': ['min', 'max', 'mean'],\n",
    "    'humidity': 'mean',\n",
    "    'windspeed': 'mean',\n",
    "    'sealevelpressure': 'mean',\n",
    "    'weather_code': lambda x: x.mode()[0],  # Dominan weather_code\n",
    "    'rain': 'sum'  # Total curah hujan\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "df_daily.columns = ['year', 'month', 'day', \n",
    "                    'temp_min', 'temp_max', 'temp_mean',\n",
    "                    'humidity_avg', 'windspeed_avg', 'pressure_avg',\n",
    "                    'weather_code_dominant', 'rain_total']\n",
    "\n",
    "print(f\"\ud83d\udcca Dataset Daily: {len(df_daily):,} baris (hari)\")\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding untuk 'weather_code_dominant' (PENTING untuk XGBoost)\n",
    "le_weather_code_daily = LabelEncoder()\n",
    "df_daily['weather_code_dominant_encoded'] = le_weather_code_daily.fit_transform(df_daily['weather_code_dominant'])\n",
    "\n",
    "print(\"\ud83d\udcdd Label Encoding untuk 'weather_code_dominant':\")\n",
    "for i, label in enumerate(le_weather_code_daily.classes_):\n",
    "    print(f\"   {i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Daily - Lag Features\n",
    "df_daily['temp_min_lag_1'] = df_daily['temp_min'].shift(1)   # Kemarin\n",
    "df_daily['temp_max_lag_1'] = df_daily['temp_max'].shift(1)\n",
    "df_daily['temp_mean_lag_1'] = df_daily['temp_mean'].shift(1)\n",
    "df_daily['humidity_avg_lag_1'] = df_daily['humidity_avg'].shift(1)\n",
    "df_daily['windspeed_avg_lag_1'] = df_daily['windspeed_avg'].shift(1)\n",
    "df_daily['pressure_avg_lag_1'] = df_daily['pressure_avg'].shift(1)\n",
    "\n",
    "df_daily['temp_min_lag_7'] = df_daily['temp_min'].shift(7)   # Seminggu lalu\n",
    "df_daily['temp_max_lag_7'] = df_daily['temp_max'].shift(7)\n",
    "df_daily['temp_mean_lag_7'] = df_daily['temp_mean'].shift(7)\n",
    "df_daily['rain_total_lag_1'] = df_daily['rain_total'].shift(1)\n",
    "\n",
    "# Hapus NaN\n",
    "rows_before = len(df_daily)\n",
    "df_daily = df_daily.dropna().reset_index(drop=True)\n",
    "rows_after = len(df_daily)\n",
    "\n",
    "print(f\"\ud83d\uddd1\ufe0f Baris dihapus (NaN): {rows_before - rows_after:,}\")\n",
    "print(f\"\ud83d\udcca Dataset Daily final: {rows_after:,} baris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pelatihan dan Perbandingan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Pemisahan Data (Time-Series Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== HOURLY DATA SPLIT =====\n",
    "hourly_train_size = int(len(df_hourly) * 0.8)\n",
    "hourly_train = df_hourly[:hourly_train_size]\n",
    "hourly_test = df_hourly[hourly_train_size:]\n",
    "\n",
    "print(f\"\ud83d\udcca HOURLY Data Split (80-20):\")\n",
    "print(f\"   Train: {len(hourly_train):,} baris\")\n",
    "print(f\"   Test:  {len(hourly_test):,} baris\")\n",
    "\n",
    "# ===== DAILY DATA SPLIT =====\n",
    "daily_train_size = int(len(df_daily) * 0.8)\n",
    "daily_train = df_daily[:daily_train_size]\n",
    "daily_test = df_daily[daily_train_size:]\n",
    "\n",
    "print(f\"\\n\ud83d\udcca DAILY Data Split (80-20):\")\n",
    "print(f\"   Train: {len(daily_train):,} baris\")\n",
    "print(f\"   Test:  {len(daily_test):,} baris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analisis Hasil dan Kinerja Individual Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Evaluasi Per-Parameter (Regresi Hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi kinerja per-parameter untuk model terbaik (Hourly)\n",
    "print(\"=\"*70)\n",
    "print(\"EVALUASI PER-PARAMETER (REGRESI HOURLY)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Gunakan model terbaik dari perbandingan\n",
    "best_reg_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "best_reg_model.fit(X_hourly_train, y_hourly_train_reg)\n",
    "y_pred = best_reg_model.predict(X_hourly_test)\n",
    "\n",
    "# Evaluasi per parameter\n",
    "param_results = []\n",
    "for i, param in enumerate(hourly_target_reg):\n",
    "    mae = mean_absolute_error(y_hourly_test_reg.iloc[:, i], y_pred[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_hourly_test_reg.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_hourly_test_reg.iloc[:, i], y_pred[:, i])\n",
    "    param_results.append({\"Parameter\": param, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "df_param_results = pd.DataFrame(param_results)\n",
    "display(df_param_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Evaluasi Klasifikasi (Weather Code) - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix untuk klasifikasi weather_code\n",
    "best_clf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "best_clf_model.fit(X_hourly_train, y_hourly_train_clf)\n",
    "y_pred_clf = best_clf_model.predict(X_hourly_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_hourly_test_clf, y_pred_clf)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=le_weather_code.classes_,\n",
    "            yticklabels=le_weather_code.classes_)\n",
    "plt.title(\"Confusion Matrix - Weather Code Classification (Hourly)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_hourly_test_clf, y_pred_clf,\n",
    "                          target_names=[str(c) for c in le_weather_code.classes_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Evaluasi Per-Parameter (Regresi Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi kinerja per-parameter untuk model terbaik (Daily)\n",
    "print(\"=\"*70)\n",
    "print(\"EVALUASI PER-PARAMETER (REGRESI DAILY)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_daily_reg = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "best_daily_reg.fit(X_daily_train, y_daily_train_reg)\n",
    "y_pred_daily = best_daily_reg.predict(X_daily_test)\n",
    "\n",
    "daily_param_results = []\n",
    "for i, param in enumerate(daily_target_reg):\n",
    "    mae = mean_absolute_error(y_daily_test_reg.iloc[:, i], y_pred_daily[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_daily_test_reg.iloc[:, i], y_pred_daily[:, i]))\n",
    "    r2 = r2_score(y_daily_test_reg.iloc[:, i], y_pred_daily[:, i])\n",
    "    daily_param_results.append({\"Parameter\": param, \"MAE\": mae, \"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "df_daily_param = pd.DataFrame(daily_param_results)\n",
    "display(df_daily_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Retraining dengan Seluruh Dataset (Final Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabung train + test untuk final training\n",
    "X_hourly_full = df_hourly[hourly_feature_cols]\n",
    "y_hourly_reg_full = df_hourly[hourly_target_reg]\n",
    "y_hourly_clf_full = df_hourly[hourly_target_clf]\n",
    "\n",
    "X_daily_full = df_daily[daily_feature_cols]\n",
    "y_daily_reg_full = df_daily[daily_target_reg]\n",
    "y_daily_clf_full = df_daily[daily_target_clf]\n",
    "\n",
    "print(f\"Full Hourly Data: {len(X_hourly_full):,} baris\")\n",
    "print(f\"Full Daily Data: {len(X_daily_full):,} baris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Final Models dengan 100% Data\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING FINAL MODELS (100% DATA)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# HOURLY Models\n",
    "print(\"Training Hourly Regressor...\")\n",
    "hourly_regressor = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "hourly_regressor.fit(X_hourly_full, y_hourly_reg_full)\n",
    "print(\"   Hourly Regressor trained\")\n",
    "\n",
    "print(\"Training Hourly Classifier...\")\n",
    "hourly_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "hourly_classifier.fit(X_hourly_full, y_hourly_clf_full)\n",
    "print(\"   Hourly Classifier trained\")\n",
    "\n",
    "# DAILY Models\n",
    "print(\"Training Daily Regressor...\")\n",
    "daily_regressor = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "daily_regressor.fit(X_daily_full, y_daily_reg_full)\n",
    "print(\"   Daily Regressor trained\")\n",
    "\n",
    "print(\"Training Daily Classifier...\")\n",
    "daily_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "daily_classifier.fit(X_daily_full, y_daily_clf_full)\n",
    "print(\"   Daily Classifier trained\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ALL 4 FINAL MODELS TRAINED SUCCESSFULLY!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Penyimpanan Model Terbaik (7 File .pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan folder models ada\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Weather code to rain mapping\n",
    "weather_code_to_rain = {0:0, 1:0, 2:0, 3:0, 51:0.2, 53:0.7, 55:1.1, 61:1.7, 63:4.0, 65:10.3}\n",
    "\n",
    "# 1. COMBINED MODEL\n",
    "combined_package = {\n",
    "    \"hourly\": {\n",
    "        \"regressor\": hourly_regressor,\n",
    "        \"classifier\": hourly_classifier,\n",
    "        \"feature_columns\": hourly_feature_cols,\n",
    "        \"target_regression\": hourly_target_reg,\n",
    "        \"target_classification\": \"weather_code\",\n",
    "    },\n",
    "    \"daily\": {\n",
    "        \"regressor\": daily_regressor,\n",
    "        \"classifier\": daily_classifier,\n",
    "        \"feature_columns\": daily_feature_cols,\n",
    "        \"target_regression\": daily_target_reg,\n",
    "        \"target_classification\": \"weather_code_dominant\",\n",
    "    },\n",
    "    \"label_encoder_hourly\": le_weather_code,\n",
    "    \"label_encoder_daily\": le_weather_code_daily,\n",
    "    \"label_encoder_conditions\": le_conditions,\n",
    "    \"weather_code_to_rain\": weather_code_to_rain,\n",
    "    \"version\": \"2.1\",\n",
    "    \"trained_date\": datetime.now().isoformat(),\n",
    "    \"model_type\": \"combined\"\n",
    "}\n",
    "joblib.dump(combined_package, \"models/weather_model_combined.pkl\")\n",
    "print(\"1. Combined model saved\")\n",
    "\n",
    "# 2. HOURLY MODEL\n",
    "hourly_package = {\n",
    "    \"regressor\": hourly_regressor,\n",
    "    \"classifier\": hourly_classifier,\n",
    "    \"feature_columns\": hourly_feature_cols,\n",
    "    \"target_regression\": hourly_target_reg,\n",
    "    \"target_classification\": \"weather_code\",\n",
    "    \"label_encoder\": le_weather_code,\n",
    "    \"label_encoder_conditions\": le_conditions,\n",
    "    \"weather_code_to_rain\": weather_code_to_rain,\n",
    "    \"version\": \"2.1\",\n",
    "    \"trained_date\": datetime.now().isoformat(),\n",
    "    \"model_type\": \"hourly\"\n",
    "}\n",
    "joblib.dump(hourly_package, \"models/weather_model_hourly.pkl\")\n",
    "print(\"2. Hourly model saved\")\n",
    "\n",
    "# 3. DAILY MODEL\n",
    "daily_package = {\n",
    "    \"regressor\": daily_regressor,\n",
    "    \"classifier\": daily_classifier,\n",
    "    \"feature_columns\": daily_feature_cols,\n",
    "    \"target_regression\": daily_target_reg,\n",
    "    \"target_classification\": \"weather_code_dominant\",\n",
    "    \"label_encoder\": le_weather_code_daily,\n",
    "    \"weather_code_to_rain\": weather_code_to_rain,\n",
    "    \"version\": \"2.1\",\n",
    "    \"trained_date\": datetime.now().isoformat(),\n",
    "    \"model_type\": \"daily\"\n",
    "}\n",
    "joblib.dump(daily_package, \"models/weather_model_daily.pkl\")\n",
    "print(\"3. Daily model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-7. SEPARATE REGRESSOR & CLASSIFIER FILES\n",
    "\n",
    "# 4. Hourly Regressor Only\n",
    "hourly_reg_package = {\n",
    "    \"model\": hourly_regressor,\n",
    "    \"feature_columns\": hourly_feature_cols,\n",
    "    \"target\": hourly_target_reg,\n",
    "    \"version\": \"2.1\",\n",
    "    \"model_type\": \"hourly_regressor\"\n",
    "}\n",
    "joblib.dump(hourly_reg_package, \"models/weather_model_hourly_regressor.pkl\")\n",
    "print(\"4. Hourly regressor saved\")\n",
    "\n",
    "# 5. Hourly Classifier Only\n",
    "hourly_clf_package = {\n",
    "    \"model\": hourly_classifier,\n",
    "    \"feature_columns\": hourly_feature_cols,\n",
    "    \"target\": \"weather_code\",\n",
    "    \"label_encoder\": le_weather_code,\n",
    "    \"weather_code_to_rain\": weather_code_to_rain,\n",
    "    \"version\": \"2.1\",\n",
    "    \"model_type\": \"hourly_classifier\"\n",
    "}\n",
    "joblib.dump(hourly_clf_package, \"models/weather_model_hourly_classifier.pkl\")\n",
    "print(\"5. Hourly classifier saved\")\n",
    "\n",
    "# 6. Daily Regressor Only\n",
    "daily_reg_package = {\n",
    "    \"model\": daily_regressor,\n",
    "    \"feature_columns\": daily_feature_cols,\n",
    "    \"target\": daily_target_reg,\n",
    "    \"version\": \"2.1\",\n",
    "    \"model_type\": \"daily_regressor\"\n",
    "}\n",
    "joblib.dump(daily_reg_package, \"models/weather_model_daily_regressor.pkl\")\n",
    "print(\"6. Daily regressor saved\")\n",
    "\n",
    "# 7. Daily Classifier Only\n",
    "daily_clf_package = {\n",
    "    \"model\": daily_classifier,\n",
    "    \"feature_columns\": daily_feature_cols,\n",
    "    \"target\": \"weather_code_dominant\",\n",
    "    \"label_encoder\": le_weather_code_daily,\n",
    "    \"weather_code_to_rain\": weather_code_to_rain,\n",
    "    \"version\": \"2.1\",\n",
    "    \"model_type\": \"daily_classifier\"\n",
    "}\n",
    "joblib.dump(daily_clf_package, \"models/weather_model_daily_classifier.pkl\")\n",
    "print(\"7. Daily classifier saved\")\n",
    "\n",
    "print(f\"\\nTotal: 7 model files created in models/ folder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Step Forecasting (Recursive Strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_forecast_hourly(model_reg, model_clf, last_known_data, feature_cols, n_hours=24):\n",
    "    \"\"\"\n",
    "    Prediksi cuaca secara rekursif untuk n_hours ke depan.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    current_data = last_known_data.copy()\n",
    "    \n",
    "    for i in range(n_hours):\n",
    "        X = current_data[feature_cols].values.reshape(1, -1)\n",
    "        reg_pred = model_reg.predict(X)[0]\n",
    "        clf_pred = model_clf.predict(X)[0]\n",
    "        \n",
    "        pred_dict = {\n",
    "            \"hour_ahead\": i + 1,\n",
    "            \"temp\": reg_pred[0],\n",
    "            \"humidity\": reg_pred[1],\n",
    "            \"windspeed\": reg_pred[2],\n",
    "            \"sealevelpressure\": reg_pred[3],\n",
    "            \"weather_code_encoded\": clf_pred\n",
    "        }\n",
    "        predictions.append(pred_dict)\n",
    "        \n",
    "        # Update untuk iterasi berikutnya\n",
    "        current_data[\"temp_lag_1\"] = reg_pred[0]\n",
    "        current_data[\"humidity_lag_1\"] = reg_pred[1]\n",
    "        current_data[\"windspeed_lag_1\"] = reg_pred[2]\n",
    "        current_data[\"sealevelpressure_lag_1\"] = reg_pred[3]\n",
    "        current_data[\"hour\"] = (current_data[\"hour\"] + 1) % 24\n",
    "        \n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "print(\"Fungsi recursive_forecast_hourly() berhasil didefinisikan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh penggunaan recursive forecast\n",
    "last_row = hourly_test.iloc[-1:].copy()\n",
    "\n",
    "# Lakukan recursive forecast 72 jam ke depan\n",
    "forecast_df = recursive_forecast_hourly(\n",
    "    best_reg_model, \n",
    "    best_clf_model, \n",
    "    last_row, \n",
    "    hourly_feature_cols, \n",
    "    n_hours=72\n",
    ")\n",
    "\n",
    "print(\"Hasil Recursive Forecast (72 jam ke depan):\")\n",
    "display(forecast_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualisasi Multi-Step Forecast vs Aktual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi perbandingan Recursive Forecast vs Aktual\n",
    "actual_72h = hourly_test.tail(72).copy().reset_index(drop=True)\n",
    "\n",
    "start_point = hourly_test.iloc[-73:-72].copy()\n",
    "forecast_72h = recursive_forecast_hourly(\n",
    "    best_reg_model, \n",
    "    best_clf_model, \n",
    "    start_point, \n",
    "    hourly_feature_cols, \n",
    "    n_hours=72\n",
    ")\n",
    "\n",
    "# Plot perbandingan\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "params = [\"temp\", \"humidity\", \"windspeed\", \"sealevelpressure\"]\n",
    "titles = [\"Temperature (C)\", \"Humidity (%)\", \"Wind Speed (km/h)\", \"Pressure (hPa)\"]\n",
    "\n",
    "for ax, param, title in zip(axes.flatten(), params, titles):\n",
    "    ax.plot(range(72), actual_72h[param].values, \"b-\", label=\"Aktual\", linewidth=2)\n",
    "    ax.plot(range(72), forecast_72h[param].values, \"r--\", label=\"Prediksi Rekursif\", linewidth=2)\n",
    "    ax.set_title(f\"{title} - Actual vs Recursive Forecast\")\n",
    "    ax.set_xlabel(\"Hours Ahead\")\n",
    "    ax.set_ylabel(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Multi-Step Recursive Forecast vs Actual (72 Hours)\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualisasi Dampak Data Inkremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrasi Incremental Learning\n",
    "print(\"=\"*70)\n",
    "print(\"ANALISIS DAMPAK DATA INKREMENTAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fractions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "r2_scores = []\n",
    "\n",
    "for frac in fractions:\n",
    "    n_samples = int(len(X_hourly_train) * frac)\n",
    "    X_subset = X_hourly_train.iloc[:n_samples]\n",
    "    y_subset = y_hourly_train_reg.iloc[:n_samples]\n",
    "    \n",
    "    temp_model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    temp_model.fit(X_subset, y_subset)\n",
    "    \n",
    "    y_pred = temp_model.predict(X_hourly_test)\n",
    "    r2 = r2_score(y_hourly_test_reg, y_pred)\n",
    "    r2_scores.append(r2)\n",
    "    \n",
    "    print(f\"   {int(frac*100):3d}% data ({n_samples:,} samples): R2 = {r2:.4f}\")\n",
    "\n",
    "# Plot hasil\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([f*100 for f in fractions], r2_scores, \"bo-\", linewidth=2, markersize=8)\n",
    "plt.xlabel(\"Percentage of Training Data (%)\", fontsize=12)\n",
    "plt.ylabel(\"R2 Score on Test Set\", fontsize=12)\n",
    "plt.title(\"Impact of Incremental Data on Model Performance\", fontsize=14, fontweight=\"bold\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks([f*100 for f in fractions])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nInsight: Model performance increases from R2={r2_scores[0]:.4f} (10%) to R2={r2_scores[-1]:.4f} (100%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rangkuman\n",
    "\n",
    "Notebook ini telah menyelesaikan:\n",
    "\n",
    "1. **Persiapan Lingkungan** - Import semua pustaka\n",
    "2. **Pemuatan Data** - Load dataset 23 kolom\n",
    "3. **EDA** - Analisis distribusi, korelasi\n",
    "4. **Feature Engineering** - Lag features untuk Hourly dan Daily\n",
    "5. **Perbandingan Model** - 5 model regresi & 4 model klasifikasi\n",
    "6. **Analisis Kinerja** - Evaluasi per-parameter dan Confusion Matrix\n",
    "7. **Retraining & Penyimpanan** - 7 file model `.pkl` tersimpan\n",
    "8. **Multi-Step Forecasting** - Recursive strategy\n",
    "9. **Visualisasi Forecast** - Actual vs Predicted\n",
    "10. **Dampak Inkremental** - R2 vs data size\n",
    "\n",
    "**Output Files:**\n",
    "```\n",
    "models/\n",
    "|- weather_model_combined.pkl\n",
    "|- weather_model_hourly.pkl\n",
    "|- weather_model_daily.pkl\n",
    "|- weather_model_hourly_regressor.pkl\n",
    "|- weather_model_hourly_classifier.pkl\n",
    "|- weather_model_daily_regressor.pkl\n",
    "|- weather_model_daily_classifier.pkl\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}