{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Weather Model Training (V2.0)\n",
    "\n",
    "This notebook implements the advanced training pipeline for the Weather IoT project (Version 2.0), strictly following the `training_guide.md`.\n",
    "\n",
    "**Structure:**\n",
    "1.  **Environment Setup**: Import libraries.\n",
    "2.  **Data Loading**: Load and sort hourly data.\n",
    "3.  **Preprocessing & Feature Engineering**: \n",
    "    - Lag features & Rolling means for ALL targets.\n",
    "    - **Cyclical Features**: Sin/Cos transformation for time.\n",
    "4.  **Model Training & Comparison**: \n",
    "    - Split architecture (Regression & Classification).\n",
    "    - **Comparison**: Uses a **subset** of data for faster evaluation.\n",
    "5.  **Analysis & Final Training**: \n",
    "    - **Final Training**: Uses the **FULL** training dataset.\n",
    "    - Individual parameter performance analysis.\n",
    "6.  **Model Saving**: Save as `weather_model_v2.pkl`.\n",
    "7.  **Visualization**: Actual vs Predicted (Jan 2020 Daily Aggregation).\n",
    "8.  **Incremental Learning**: Impact of data size on accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Persiapan Lingkungan dan Pemuatan Pustaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pengumpulan dan Pemuatan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_path = '../data/historical_data_hourly.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Ensure timestamp is datetime and sort chronologically\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(\"Data Structure:\")\n",
    "df.info()\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pra-pemrosesan Data dan Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Label Encoding for Weather Condition\n",
    "# We use the original weather_code. LabelEncoder ensures they are 0..N-1 for some algorithms.\n",
    "le = LabelEncoder()\n",
    "df['weather_code_encoded'] = le.fit_transform(df['weather_code'])\n",
    "\n",
    "# 2. Feature Engineering: Lag and Rolling Mean\n",
    "targets_reg = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "\n",
    "for col in targets_reg:\n",
    "    # Lag Features\n",
    "    df[f'{col}_lag_1'] = df[col].shift(1)\n",
    "    df[f'{col}_lag_24'] = df[col].shift(24)\n",
    "    \n",
    "    # Rolling Mean Features (24 hour window)\n",
    "    df[f'{col}_rolling_24'] = df[col].rolling(window=24).mean()\n",
    "\n",
    "# 3. Cyclical Time Features\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "# Time features (Keep original for reference/other models)\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "# 4. Handle NaN values\n",
    "df_clean = df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"Data after Feature Engineering:\")\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Pelatihan dan Perbandingan Model (Subset Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features and Targets\n",
    "feature_cols = ['year', 'month', 'day', 'hour', 'hour_sin', 'hour_cos', 'month_sin', 'month_cos']\n",
    "for col in targets_reg:\n",
    "    feature_cols.extend([f'{col}_lag_1', f'{col}_lag_24', f'{col}_rolling_24'])\n",
    "\n",
    "target_class = 'weather_code_encoded'\n",
    "\n",
    "X = df_clean[feature_cols]\n",
    "y_reg = df_clean[targets_reg]\n",
    "y_class = df_clean[target_class]\n",
    "\n",
    "# --- Time Series Split Strategy ---\n",
    "# 1. Full Split: 80% Train, 20% Test (Strict Temporal)\n",
    "split_index = int(len(df_clean) * 0.8)\n",
    "\n",
    "X_train_full = X.iloc[:split_index]\n",
    "X_test_full = X.iloc[split_index:]\n",
    "\n",
    "y_reg_train_full = y_reg.iloc[:split_index]\n",
    "y_reg_test_full = y_reg.iloc[split_index:]\n",
    "\n",
    "y_class_train_full = y_class.iloc[:split_index]\n",
    "y_class_test_full = y_class.iloc[split_index:]\n",
    "\n",
    "# 2. Subset Split for Comparison\n",
    "subset_size = 5000\n",
    "X_train_sub = X_train_full.iloc[-subset_size:]\n",
    "y_reg_train_sub = y_reg_train_full.iloc[-subset_size:]\n",
    "y_class_train_sub = y_class_train_full.iloc[-subset_size:]\n",
    "\n",
    "X_test_sub = X_test_full.iloc[:1000]\n",
    "y_reg_test_sub = y_reg_test_full.iloc[:1000]\n",
    "y_class_test_sub = y_class_test_full.iloc[:1000]\n",
    "\n",
    "print(f\"Full Training Data: {X_train_full.shape[0]} samples\")\n",
    "print(f\"Comparison Subset Training Data: {X_train_sub.shape[0]} samples\")\n",
    "\n",
    "# --- Regression Comparison (Using Subset) ---\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'KNN': KNeighborsRegressor(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "reg_results = []\n",
    "best_reg_name = \"\"\n",
    "best_reg_score_sub = -np.inf\n",
    "\n",
    "print(\"\\nComparing Regression Models (on Subset)...\")\n",
    "for name, model in reg_models.items():\n",
    "    mor = MultiOutputRegressor(model)\n",
    "    mor.fit(X_train_sub, y_reg_train_sub)\n",
    "    y_pred = mor.predict(X_test_sub)\n",
    "    \n",
    "    r2 = r2_score(y_reg_test_sub, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_reg_test_sub, y_pred))\n",
    "    \n",
    "    reg_results.append({'Model': name, 'R2': r2, 'RMSE': rmse})\n",
    "    \n",
    "    if r2 > best_reg_score_sub:\n",
    "        best_reg_score_sub = r2\n",
    "        best_reg_name = name\n",
    "\n",
    "display(pd.DataFrame(reg_results))\n",
    "print(f\"Best Regression Model (Candidate): {best_reg_name}\")\n",
    "\n",
    "# --- Classification Comparison (Using Subset) ---\n",
    "# Using class_weight='balanced' to help with performance on original codes\n",
    "class_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, n_jobs=-1, class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "}\n",
    "\n",
    "class_results = []\n",
    "best_class_name = \"\"\n",
    "best_class_score_sub = -np.inf\n",
    "\n",
    "print(\"\\nComparing Classification Models (on Subset)...\")\n",
    "for name, model in class_models.items():\n",
    "    model.fit(X_train_sub, y_class_train_sub)\n",
    "    y_pred = model.predict(X_test_sub)\n",
    "    \n",
    "    acc = accuracy_score(y_class_test_sub, y_pred)\n",
    "    class_results.append({'Model': name, 'Accuracy': acc})\n",
    "    \n",
    "    if acc > best_class_score_sub:\n",
    "        best_class_score_sub = acc\n",
    "        best_class_name = name\n",
    "\n",
    "display(pd.DataFrame(class_results))\n",
    "print(f\"Best Classification Model (Candidate): {best_class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Hyperparameter Tuning & Final Training (Full Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Final Training on FULL Dataset ---\")\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "# 1. Train Best Regressor on Full Data\n",
    "print(f\"Training {best_reg_name} on Full Data...\")\n",
    "\n",
    "if 'Random Forest' in best_reg_name:\n",
    "    # Simple Grid Search for RF\n",
    "    param_grid_reg = {'estimator__n_estimators': [100], 'estimator__max_depth': [20, None]}\n",
    "    base_reg = MultiOutputRegressor(RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "    grid_reg = GridSearchCV(base_reg, param_grid_reg, cv=tscv, scoring='r2', n_jobs=-1)\n",
    "    grid_reg.fit(X_train_full, y_reg_train_full)\n",
    "    best_reg_model_final = grid_reg.best_estimator_\n",
    "else:\n",
    "    # Fallback for other models (Linear, etc.) - just fit\n",
    "    if 'Linear' in best_reg_name: base_reg = MultiOutputRegressor(LinearRegression())\n",
    "    elif 'KNN' in best_reg_name: base_reg = MultiOutputRegressor(KNeighborsRegressor())\n",
    "    else: base_reg = MultiOutputRegressor(DecisionTreeRegressor(random_state=42))\n",
    "    \n",
    "    base_reg.fit(X_train_full, y_reg_train_full)\n",
    "    best_reg_model_final = base_reg\n",
    "\n",
    "# 2. Train Best Classifier on Full Data\n",
    "print(f\"Training {best_class_name} on Full Data...\")\n",
    "\n",
    "if 'Random Forest' in best_class_name:\n",
    "    param_grid_class = {'n_estimators': [100], 'max_depth': [20, None]}\n",
    "    base_class = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "    grid_class = GridSearchCV(base_class, param_grid_class, cv=tscv, scoring='accuracy', n_jobs=-1)\n",
    "    grid_class.fit(X_train_full, y_class_train_full)\n",
    "    best_class_model_final = grid_class.best_estimator_\n",
    "else:\n",
    "    if 'Logistic' in best_class_name: base_class = LogisticRegression(max_iter=1000, n_jobs=-1, class_weight='balanced')\n",
    "    else: base_class = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "    \n",
    "    base_class.fit(X_train_full, y_class_train_full)\n",
    "    best_class_model_final = base_class\n",
    "\n",
    "print(\"Final Models Trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Analisis Hasil dan Kinerja Individual Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on Full Test Set\n",
    "y_reg_pred_final = best_reg_model_final.predict(X_test_full)\n",
    "y_class_pred_final = best_class_model_final.predict(X_test_full)\n",
    "\n",
    "print(\"--- Individual Parameter Performance (Regression - Full Test) ---\")\n",
    "param_metrics = []\n",
    "for i, col in enumerate(targets_reg):\n",
    "    r2 = r2_score(y_reg_test_full.iloc[:, i], y_reg_pred_final[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_reg_test_full.iloc[:, i], y_reg_pred_final[:, i]))\n",
    "    mae = mean_absolute_error(y_reg_test_full.iloc[:, i], y_reg_pred_final[:, i])\n",
    "    param_metrics.append({'Parameter': col, 'R2': r2, 'RMSE': rmse, 'MAE': mae})\n",
    "\n",
    "display(pd.DataFrame(param_metrics))\n",
    "\n",
    "print(\"\\n--- Classification Performance (Full Test) ---\")\n",
    "print(classification_report(y_class_test_full, y_class_pred_final, target_names=le.classes_.astype(str)))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_class_test_full, y_class_pred_final)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.title('Confusion Matrix: Weather Conditions')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Penyimpanan Model Terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "artifacts = {\n",
    "    'regressor': best_reg_model_final,\n",
    "    'classifier': best_class_model_final,\n",
    "    'label_encoder': le,\n",
    "    'features': feature_cols,\n",
    "    'targets_reg': targets_reg,\n",
    "    'version': '2.0'\n",
    "}\n",
    "\n",
    "save_dir = '../models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "filename = os.path.join(save_dir, 'weather_model_v2.pkl')\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(artifacts, f)\n",
    "\n",
    "print(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Visualisasi Perbandingan Aktual vs. Prediksi (Januari 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for visualization (e.g., first 30 days of test data)\n",
    "test_df = df_clean.iloc[X_test_full.index].copy()\n",
    "test_df['pred_temp'] = y_reg_pred_final[:, 0]\n",
    "test_df['pred_humidity'] = y_reg_pred_final[:, 1]\n",
    "test_df['pred_windspeed'] = y_reg_pred_final[:, 2]\n",
    "test_df['pred_pressure'] = y_reg_pred_final[:, 3]\n",
    "\n",
    "# Resample to Daily Mean for cleaner plots\n",
    "daily_df = test_df.set_index('timestamp').resample('D').mean(numeric_only=True)\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 20))\n",
    "\n",
    "params = [\n",
    "    ('temp', 'pred_temp', 'Temperature (Â°C)'),\n",
    "    ('humidity', 'pred_humidity', 'Humidity (%)'),\n",
    "    ('windspeed', 'pred_windspeed', 'Wind Speed (km/h)'),\n",
    "    ('sealevelpressure', 'pred_pressure', 'Pressure (hPa)')\n",
    "]\n",
    "\n",
    "for i, (actual, pred, label) in enumerate(params):\n",
    "    ax = axes[i]\n",
    "    # Plot only first 30 days\n",
    "    plot_data = daily_df.iloc[:30]\n",
    "    \n",
    "    ax.plot(plot_data.index, plot_data[actual], label='Actual', color='blue', linewidth=2)\n",
    "    ax.plot(plot_data.index, plot_data[pred], label='Predicted', color='red', linestyle='--', linewidth=2)\n",
    "    ax.set_title(f'Actual vs Predicted: {label}')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(label)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Visualisasi Dampak Data Inkremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate Incremental Learning using Full Training Data\n",
    "fractions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "r2_scores = []\n",
    "\n",
    "print(\"Simulating Incremental Learning...\")\n",
    "for frac in fractions:\n",
    "    # Use a fraction of the full training data (chronologically)\n",
    "    subset_size = int(len(X_train_full) * frac)\n",
    "    X_subset = X_train_full.iloc[:subset_size]\n",
    "    y_subset = y_reg_train_full.iloc[:subset_size]\n",
    "    \n",
    "    # Train model on subset (using best regressor type)\n",
    "    if 'Random Forest' in best_reg_name:\n",
    "        model = MultiOutputRegressor(RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1))\n",
    "    else:\n",
    "        model = MultiOutputRegressor(LinearRegression())\n",
    "        \n",
    "    model.fit(X_subset, y_subset)\n",
    "    \n",
    "    # Evaluate on full test set\n",
    "    y_pred_subset = model.predict(X_test_full)\n",
    "    score = r2_score(y_reg_test_full, y_pred_subset)\n",
    "    r2_scores.append(score)\n",
    "\n",
    "# Plot Trend\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.array(fractions) * 100, r2_scores, marker='o', color='green', linewidth=2)\n",
    "plt.title('Impact of Incremental Data on Model Performance (R2 Score)')\n",
    "plt.xlabel('Percentage of Training Data Used (%)')\n",
    "plt.ylabel('R2 Score on Test Set')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
