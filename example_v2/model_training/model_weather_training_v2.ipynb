{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Model Training v2.0 - Complete Implementation\n",
    "\n",
    "Implementasi lengkap mengikuti `training_guide_v2.md`:\n",
    "- Cyclical Time Features (Sin/Cos)\n",
    "- Interaction Features (Dew Point)\n",
    "- Class Balancing (`class_weight='balanced'`)\n",
    "- Expanding Window Cross-Validation\n",
    "- Daily Model (agregasi + training)\n",
    "- Visualisasi Januari 2022 (gap 2 hari)\n",
    "- 7 File Model Output\n",
    "- Multi-Step Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Persiapan Lingkungan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor, XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "import joblib\n",
    "print(f\"Libraries loaded | XGBoost: {XGBOOST_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/historical_data_2000_2024.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "print(f\"Dataset: {len(df):,} rows x {len(df.columns)} cols\")\n",
    "print(f\"Range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Statistik Deskriptif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Distribusi Parameter Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "params = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "titles = ['Temperature (C)', 'Humidity (%)', 'Wind Speed (km/h)', 'Pressure (hPa)']\n",
    "for ax, param, title in zip(axes.flatten(), params, titles):\n",
    "    sns.histplot(df[param], kde=True, ax=ax, color='steelblue')\n",
    "    ax.set_title(f'Distribusi {title}')\n",
    "plt.suptitle('Distribusi Parameter Cuaca Hourly', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Korelasi Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure', 'rain', 'weather_code']\n",
    "sns.heatmap(df[cols].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Weather Code vs Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('weather_code')[['rain']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = df.copy()\n",
    "le_conditions = LabelEncoder()\n",
    "df_hourly['conditions_encoded'] = le_conditions.fit_transform(df_hourly['conditions'])\n",
    "le_weather_code = LabelEncoder()\n",
    "df_hourly['weather_code_encoded'] = le_weather_code.fit_transform(df_hourly['weather_code'])\n",
    "print(\"Label encoding done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 [v2.0] Cyclical Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly['hour_sin'] = np.sin(2 * np.pi * df_hourly['hour'] / 24)\n",
    "df_hourly['hour_cos'] = np.cos(2 * np.pi * df_hourly['hour'] / 24)\n",
    "df_hourly['month_sin'] = np.sin(2 * np.pi * df_hourly['month'] / 12)\n",
    "df_hourly['month_cos'] = np.cos(2 * np.pi * df_hourly['month'] / 12)\n",
    "df_hourly['day_of_year'] = df_hourly['timestamp'].dt.dayofyear\n",
    "df_hourly['doy_sin'] = np.sin(2 * np.pi * df_hourly['day_of_year'] / 365)\n",
    "df_hourly['doy_cos'] = np.cos(2 * np.pi * df_hourly['day_of_year'] / 365)\n",
    "print(\"Cyclical features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 [v2.0] Interaction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly['dew_point'] = df_hourly['temp'] - ((100 - df_hourly['humidity']) / 5)\n",
    "df_hourly['temp_range'] = df_hourly['temp_max_daily'] - df_hourly['temp_min_daily']\n",
    "df_hourly['humid_temp_ratio'] = df_hourly['humidity'] / (df_hourly['temp'] + 1)\n",
    "print(\"Interaction features created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Lag Features Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "for col in cols:\n",
    "    df_hourly[f'{col}_lag_1'] = df_hourly[col].shift(1)\n",
    "    df_hourly[f'{col}_lag_24'] = df_hourly[col].shift(24)\n",
    "    df_hourly[f'{col}_rolling_24'] = df_hourly[col].rolling(24).mean()\n",
    "    df_hourly[f'{col}_rolling_std_24'] = df_hourly[col].rolling(24).std()\n",
    "\n",
    "df_hourly = df_hourly.dropna().reset_index(drop=True)\n",
    "print(f\"Hourly: {len(df_hourly):,} rows after dropna\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 [v2.0] Preprocessing Data Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregasi hourly ke daily\n",
    "df_daily = df.groupby(['year', 'month', 'day']).agg({\n",
    "    'temp': ['min', 'max', 'mean'],\n",
    "    'humidity': 'mean',\n",
    "    'windspeed': 'mean',\n",
    "    'sealevelpressure': 'mean',\n",
    "    'weather_code': lambda x: x.mode()[0],\n",
    "    'rain': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "df_daily.columns = ['year', 'month', 'day', 'temp_min', 'temp_max', 'temp_mean',\n",
    "                    'humidity_avg', 'windspeed_avg', 'pressure_avg',\n",
    "                    'weather_code_dominant', 'rain_total']\n",
    "\n",
    "le_weather_code_daily = LabelEncoder()\n",
    "df_daily['weather_code_dominant_encoded'] = le_weather_code_daily.fit_transform(df_daily['weather_code_dominant'])\n",
    "print(f\"Daily: {len(df_daily):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 [v2.0] Lag Features Daily dengan Rolling 3d/7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag 1 day\n",
    "for col in ['temp_min', 'temp_max', 'temp_mean', 'humidity_avg', 'windspeed_avg', 'pressure_avg']:\n",
    "    df_daily[f'{col}_lag_1'] = df_daily[col].shift(1)\n",
    "\n",
    "# Lag 7 days\n",
    "df_daily['temp_min_lag_7'] = df_daily['temp_min'].shift(7)\n",
    "df_daily['temp_max_lag_7'] = df_daily['temp_max'].shift(7)\n",
    "df_daily['temp_mean_lag_7'] = df_daily['temp_mean'].shift(7)\n",
    "df_daily['rain_total_lag_1'] = df_daily['rain_total'].shift(1)\n",
    "\n",
    "# Rolling 3d/7d\n",
    "df_daily['temp_rolling_3d'] = df_daily['temp_mean'].rolling(3).mean()\n",
    "df_daily['temp_rolling_7d'] = df_daily['temp_mean'].rolling(7).mean()\n",
    "df_daily['humidity_rolling_3d'] = df_daily['humidity_avg'].rolling(3).mean()\n",
    "df_daily['humidity_rolling_7d'] = df_daily['humidity_avg'].rolling(7).mean()\n",
    "\n",
    "df_daily = df_daily.dropna().reset_index(drop=True)\n",
    "print(f\"Daily after features: {len(df_daily):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 [v2.0] Expanding Window Cross-Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def evaluate_with_cv(model, X, y):\n",
    "    \"\"\"Evaluasi dengan Time Series Cross-Validation\"\"\"\n",
    "    scores = {'r2': [], 'rmse': []}\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        scores['r2'].append(r2_score(y_test, y_pred))\n",
    "        scores['rmse'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    return {'R2_mean': np.mean(scores['r2']), 'R2_std': np.std(scores['r2']), 'RMSE_mean': np.mean(scores['rmse'])}\n",
    "\n",
    "print(\"CV function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Data Split (HOURLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Hourly\n",
    "hourly_feature_cols = [\n",
    "    'hour_sin', 'hour_cos', 'month_sin', 'month_cos',\n",
    "    'temp_lag_1', 'temp_lag_24', 'temp_rolling_24',\n",
    "    'humidity_lag_1', 'humidity_lag_24', 'humidity_rolling_24',\n",
    "    'windspeed_lag_1', 'windspeed_lag_24', 'windspeed_rolling_24',\n",
    "    'sealevelpressure_lag_1', 'sealevelpressure_lag_24', 'sealevelpressure_rolling_24',\n",
    "    'dew_point', 'humid_temp_ratio'\n",
    "]\n",
    "hourly_target_reg = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "hourly_target_clf = 'weather_code_encoded'\n",
    "\n",
    "train_size = int(len(df_hourly) * 0.8)\n",
    "hourly_train = df_hourly[:train_size]\n",
    "hourly_test = df_hourly[train_size:]\n",
    "\n",
    "X_hourly_train = hourly_train[hourly_feature_cols]\n",
    "X_hourly_test = hourly_test[hourly_feature_cols]\n",
    "y_hourly_train_reg = hourly_train[hourly_target_reg]\n",
    "y_hourly_test_reg = hourly_test[hourly_target_reg]\n",
    "y_hourly_train_clf = hourly_train[hourly_target_clf]\n",
    "y_hourly_test_clf = hourly_test[hourly_target_clf]\n",
    "\n",
    "print(f\"Hourly Train: {len(X_hourly_train):,} | Test: {len(X_hourly_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Data Split (DAILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Daily\n",
    "daily_feature_cols = [\n",
    "    'month', 'day',\n",
    "    'temp_min_lag_1', 'temp_max_lag_1', 'temp_mean_lag_1',\n",
    "    'humidity_avg_lag_1', 'windspeed_avg_lag_1', 'pressure_avg_lag_1',\n",
    "    'temp_min_lag_7', 'temp_max_lag_7', 'temp_mean_lag_7',\n",
    "    'rain_total_lag_1',\n",
    "    'temp_rolling_3d', 'temp_rolling_7d',\n",
    "    'humidity_rolling_3d', 'humidity_rolling_7d'\n",
    "]\n",
    "daily_target_reg = ['temp_min', 'temp_max', 'temp_mean', 'humidity_avg', 'windspeed_avg', 'pressure_avg']\n",
    "daily_target_clf = 'weather_code_dominant_encoded'\n",
    "\n",
    "daily_train_size = int(len(df_daily) * 0.8)\n",
    "daily_train = df_daily[:daily_train_size]\n",
    "daily_test = df_daily[daily_train_size:]\n",
    "\n",
    "X_daily_train = daily_train[daily_feature_cols]\n",
    "X_daily_test = daily_test[daily_feature_cols]\n",
    "y_daily_train_reg = daily_train[daily_target_reg]\n",
    "y_daily_test_reg = daily_test[daily_target_reg]\n",
    "y_daily_train_clf = daily_train[daily_target_clf]\n",
    "y_daily_test_clf = daily_test[daily_target_clf]\n",
    "\n",
    "print(f\"Daily Train: {len(X_daily_train):,} | Test: {len(X_daily_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Regression Models (HOURLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'K-Neighbors': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    regression_models['XGBoost'] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return {'MSE': mse, 'RMSE': np.sqrt(mse), 'MAE': mean_absolute_error(y_true, y_pred), 'R2': r2_score(y_true, y_pred)}\n",
    "\n",
    "reg_results = []\n",
    "for name, model in regression_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_hourly_train, y_hourly_train_reg)\n",
    "    y_pred = model.predict(X_hourly_test)\n",
    "    metrics = evaluate_regression(y_hourly_test_reg, y_pred)\n",
    "    metrics['Model'] = name\n",
    "    reg_results.append(metrics)\n",
    "\n",
    "df_hourly_reg = pd.DataFrame(reg_results).sort_values('R2', ascending=False)\n",
    "display(df_hourly_reg[['Model', 'R2', 'RMSE', 'MAE']])\n",
    "best_hourly_reg_name = df_hourly_reg.iloc[0]['Model']\n",
    "print(f\"Best Hourly Regression: {best_hourly_reg_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 [v2.0] Classification with Class Balancing (HOURLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    classification_models['XGBoost'] = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "clf_results = []\n",
    "for name, model in classification_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_hourly_train, y_hourly_train_clf)\n",
    "    y_pred = model.predict(X_hourly_test)\n",
    "    clf_results.append({'Model': name, 'Accuracy': accuracy_score(y_hourly_test_clf, y_pred), \n",
    "                        'F1': f1_score(y_hourly_test_clf, y_pred, average='weighted', zero_division=0)})\n",
    "\n",
    "df_hourly_clf = pd.DataFrame(clf_results).sort_values('Accuracy', ascending=False)\n",
    "display(df_hourly_clf)\n",
    "best_hourly_clf_name = df_hourly_clf.iloc[0]['Model']\n",
    "print(f\"Best Hourly Classification: {best_hourly_clf_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Regression Models (DAILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize models\n",
    "daily_reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    daily_reg_models['XGBoost'] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "daily_reg_results = []\n",
    "for name, model in daily_reg_models.items():\n",
    "    print(f\"Training Daily {name}...\")\n",
    "    model.fit(X_daily_train, y_daily_train_reg)\n",
    "    y_pred = model.predict(X_daily_test)\n",
    "    metrics = evaluate_regression(y_daily_test_reg, y_pred)\n",
    "    metrics['Model'] = name\n",
    "    daily_reg_results.append(metrics)\n",
    "\n",
    "df_daily_reg = pd.DataFrame(daily_reg_results).sort_values('R2', ascending=False)\n",
    "display(df_daily_reg[['Model', 'R2', 'RMSE', 'MAE']])\n",
    "best_daily_reg_name = df_daily_reg.iloc[0]['Model']\n",
    "print(f\"Best Daily Regression: {best_daily_reg_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Classification (DAILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_clf_models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    daily_clf_models['XGBoost'] = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "daily_clf_results = []\n",
    "for name, model in daily_clf_models.items():\n",
    "    print(f\"Training Daily {name}...\")\n",
    "    model.fit(X_daily_train, y_daily_train_clf)\n",
    "    y_pred = model.predict(X_daily_test)\n",
    "    daily_clf_results.append({'Model': name, 'Accuracy': accuracy_score(y_daily_test_clf, y_pred),\n",
    "                              'F1': f1_score(y_daily_test_clf, y_pred, average='weighted', zero_division=0)})\n",
    "\n",
    "df_daily_clf = pd.DataFrame(daily_clf_results).sort_values('Accuracy', ascending=False)\n",
    "display(df_daily_clf)\n",
    "print(f\"Best Daily Classification: {df_daily_clf.iloc[0]['Model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analisis Kinerja Individual Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best models\n",
    "best_reg_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "best_reg_model.fit(X_hourly_train, y_hourly_train_reg)\n",
    "\n",
    "best_clf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "best_clf_model.fit(X_hourly_train, y_hourly_train_clf)\n",
    "\n",
    "# Per-parameter evaluation\n",
    "y_pred = best_reg_model.predict(X_hourly_test)\n",
    "param_results = []\n",
    "for i, param in enumerate(hourly_target_reg):\n",
    "    mae = mean_absolute_error(y_hourly_test_reg.iloc[:, i], y_pred[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_hourly_test_reg.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_hourly_test_reg.iloc[:, i], y_pred[:, i])\n",
    "    param_results.append({'Parameter': param, 'MAE': round(mae, 4), 'RMSE': round(rmse, 4), 'R2': round(r2, 4)})\n",
    "\n",
    "display(pd.DataFrame(param_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Visualisasi Januari 2022 (Gap 2 Hari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_mask = (df_hourly['year'] == 2022) & (df_hourly['month'] == 1)\n",
    "df_jan = df_hourly[jan_mask].copy()\n",
    "\n",
    "if len(df_jan) > 0:\n",
    "    X_jan = df_jan[hourly_feature_cols]\n",
    "    y_jan_pred = best_reg_model.predict(X_jan)\n",
    "    df_jan['temp_pred'] = y_jan_pred[:, 0]\n",
    "    df_jan['humidity_pred'] = y_jan_pred[:, 1]\n",
    "    df_jan['windspeed_pred'] = y_jan_pred[:, 2]\n",
    "    df_jan['pressure_pred'] = y_jan_pred[:, 3]\n",
    "    \n",
    "    df_jan_2d = df_jan.set_index('timestamp').resample('2D').mean().reset_index()\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 16))\n",
    "    params = [('temp', 'temp_pred', 'Temperature (C)', 'red'),\n",
    "              ('humidity', 'humidity_pred', 'Humidity (%)', 'blue'),\n",
    "              ('windspeed', 'windspeed_pred', 'Wind Speed (km/h)', 'green'),\n",
    "              ('sealevelpressure', 'pressure_pred', 'Pressure (hPa)', 'purple')]\n",
    "    \n",
    "    for ax, (actual, pred, title, color) in zip(axes, params):\n",
    "        ax.plot(df_jan_2d['timestamp'], df_jan_2d[actual], '-o', color=color, label='Actual', linewidth=2)\n",
    "        ax.plot(df_jan_2d['timestamp'], df_jan_2d[pred], '--s', color=color, alpha=0.6, label='Predicted', linewidth=2)\n",
    "        ax.set_title(f'{title} - January 2022 (2-Day Gap)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/jan_2022_predictions_v2.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No data for January 2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_jan) > 0:\n",
    "    y_jan_clf_pred = best_clf_model.predict(X_jan)\n",
    "    cm = confusion_matrix(df_jan['weather_code_encoded'], y_jan_clf_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=le_weather_code.classes_, yticklabels=le_weather_code.classes_)\n",
    "    plt.title('Confusion Matrix - January 2022')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.savefig('outputs/jan_2022_confusion_v2.png', dpi=150)\n",
    "    plt.show()\n",
    "    print(classification_report(df_jan['weather_code_encoded'], y_jan_clf_pred, target_names=[str(c) for c in le_weather_code.classes_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Retraining with 100% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOURLY MODELS\n",
    "X_hourly_full = df_hourly[hourly_feature_cols]\n",
    "y_hourly_reg_full = df_hourly[hourly_target_reg]\n",
    "y_hourly_clf_full = df_hourly[hourly_target_clf]\n",
    "\n",
    "print('Training final hourly models...')\n",
    "hourly_regressor = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "hourly_regressor.fit(X_hourly_full, y_hourly_reg_full)\n",
    "\n",
    "hourly_classifier = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "hourly_classifier.fit(X_hourly_full, y_hourly_clf_full)\n",
    "\n",
    "# DAILY MODELS\n",
    "X_daily_full = df_daily[daily_feature_cols]\n",
    "y_daily_reg_full = df_daily[daily_target_reg]\n",
    "y_daily_clf_full = df_daily[daily_target_clf]\n",
    "\n",
    "print('Training final daily models...')\n",
    "daily_regressor = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "daily_regressor.fit(X_daily_full, y_daily_reg_full)\n",
    "\n",
    "daily_classifier = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "daily_classifier.fit(X_daily_full, y_daily_clf_full)\n",
    "\n",
    "print('All 4 final models trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Models (7 Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "weather_code_to_rain = {0:0, 1:0, 2:0, 3:0, 51:0.2, 53:0.7, 55:1.1, 61:1.7, 63:4.0, 65:10.3}\n",
    "\n",
    "# 1. COMBINED MODEL\n",
    "combined_package = {\n",
    "    'hourly': {\n",
    "        'regressor': hourly_regressor,\n",
    "        'classifier': hourly_classifier,\n",
    "        'feature_columns': hourly_feature_cols,\n",
    "        'target_regression': hourly_target_reg,\n",
    "        'target_classification': 'weather_code',\n",
    "    },\n",
    "    'daily': {\n",
    "        'regressor': daily_regressor,\n",
    "        'classifier': daily_classifier,\n",
    "        'feature_columns': daily_feature_cols,\n",
    "        'target_regression': daily_target_reg,\n",
    "        'target_classification': 'weather_code_dominant',\n",
    "    },\n",
    "    'label_encoder_hourly': le_weather_code,\n",
    "    'label_encoder_daily': le_weather_code_daily,\n",
    "    'label_encoder_conditions': le_conditions,\n",
    "    'weather_code_to_rain': weather_code_to_rain,\n",
    "    'cyclical_features': ['hour_sin', 'hour_cos', 'month_sin', 'month_cos'],\n",
    "    'interaction_features': ['dew_point', 'humid_temp_ratio'],\n",
    "    'version': '2.1',\n",
    "    'trained_date': datetime.now().isoformat(),\n",
    "}\n",
    "joblib.dump(combined_package, 'models/weather_model_combined.pkl')\n",
    "print('1. Combined model saved')\n",
    "\n",
    "# 2. HOURLY MODEL\n",
    "hourly_package = {\n",
    "    'regressor': hourly_regressor, 'classifier': hourly_classifier,\n",
    "    'feature_columns': hourly_feature_cols, 'target_regression': hourly_target_reg,\n",
    "    'label_encoder': le_weather_code, 'weather_code_to_rain': weather_code_to_rain, 'version': '2.1'\n",
    "}\n",
    "joblib.dump(hourly_package, 'models/weather_model_hourly.pkl')\n",
    "print('2. Hourly model saved')\n",
    "\n",
    "# 3. DAILY MODEL\n",
    "daily_package = {\n",
    "    'regressor': daily_regressor, 'classifier': daily_classifier,\n",
    "    'feature_columns': daily_feature_cols, 'target_regression': daily_target_reg,\n",
    "    'label_encoder': le_weather_code_daily, 'weather_code_to_rain': weather_code_to_rain, 'version': '2.1'\n",
    "}\n",
    "joblib.dump(daily_package, 'models/weather_model_daily.pkl')\n",
    "print('3. Daily model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-7. SEPARATE FILES\n",
    "joblib.dump({'model': hourly_regressor, 'features': hourly_feature_cols, 'target': hourly_target_reg}, \n",
    "            'models/weather_model_hourly_regressor.pkl')\n",
    "print('4. Hourly regressor saved')\n",
    "\n",
    "joblib.dump({'model': hourly_classifier, 'features': hourly_feature_cols, 'label_encoder': le_weather_code}, \n",
    "            'models/weather_model_hourly_classifier.pkl')\n",
    "print('5. Hourly classifier saved')\n",
    "\n",
    "joblib.dump({'model': daily_regressor, 'features': daily_feature_cols, 'target': daily_target_reg}, \n",
    "            'models/weather_model_daily_regressor.pkl')\n",
    "print('6. Daily regressor saved')\n",
    "\n",
    "joblib.dump({'model': daily_classifier, 'features': daily_feature_cols, 'label_encoder': le_weather_code_daily}, \n",
    "            'models/weather_model_daily_classifier.pkl')\n",
    "print('7. Daily classifier saved')\n",
    "\n",
    "print('\\n7 model files saved to models/ folder!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Step Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_forecast(model_reg, model_clf, last_row, feature_cols, n_hours=24):\n",
    "    predictions = []\n",
    "    current = last_row.copy()\n",
    "    for i in range(n_hours):\n",
    "        X = current[feature_cols].values.reshape(1, -1)\n",
    "        reg_pred = model_reg.predict(X)[0]\n",
    "        clf_pred = model_clf.predict(X)[0]\n",
    "        predictions.append({'hour': i+1, 'temp': reg_pred[0], 'humidity': reg_pred[1],\n",
    "                           'windspeed': reg_pred[2], 'pressure': reg_pred[3], 'weather_code': clf_pred})\n",
    "        current['temp_lag_1'] = reg_pred[0]\n",
    "        current['humidity_lag_1'] = reg_pred[1]\n",
    "        current['windspeed_lag_1'] = reg_pred[2]\n",
    "        current['sealevelpressure_lag_1'] = reg_pred[3]\n",
    "    return pd.DataFrame(predictions)\n",
    "\n",
    "forecast_72h = recursive_forecast(best_reg_model, best_clf_model, hourly_test.iloc[-1:], hourly_feature_cols, 72)\n",
    "print('72-hour forecast generated')\n",
    "forecast_72h.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_72h = hourly_test.tail(72).reset_index(drop=True)\n",
    "start = hourly_test.iloc[-73:-72]\n",
    "forecast = recursive_forecast(best_reg_model, best_clf_model, start, hourly_feature_cols, 72)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "params = ['temp', 'humidity', 'windspeed', 'pressure']\n",
    "actual_cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "\n",
    "for ax, param, actual_col in zip(axes.flatten(), params, actual_cols):\n",
    "    ax.plot(range(72), actual_72h[actual_col].values, 'b-', label='Actual', linewidth=2)\n",
    "    ax.plot(range(72), forecast[param].values, 'r--', label='Forecast', linewidth=2)\n",
    "    ax.set_title(f'{param} - 72h Recursive Forecast')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/recursive_forecast_72h.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Incremental Learning Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "r2_scores = []\n",
    "\n",
    "for frac in fractions:\n",
    "    n = int(len(X_hourly_train) * frac)\n",
    "    temp_model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    temp_model.fit(X_hourly_train.iloc[:n], y_hourly_train_reg.iloc[:n])\n",
    "    r2 = r2_score(y_hourly_test_reg, temp_model.predict(X_hourly_test))\n",
    "    r2_scores.append(r2)\n",
    "    print(f'{int(frac*100):3d}%: R2 = {r2:.4f}')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([f*100 for f in fractions], r2_scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('% of Training Data')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('Impact of Incremental Data on Model Performance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('outputs/incremental_learning.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Completed:\n",
    "1. Cyclical time features (Sin/Cos)\n",
    "2. Interaction features (Dew Point, Temp Range)\n",
    "3. Class balancing (`class_weight='balanced'`)\n",
    "4. Expanding Window CV function\n",
    "5. Daily model preprocessing + training\n",
    "6. January 2022 visualization (2-day gap)\n",
    "7. Multi-step recursive forecasting\n",
    "8. **7 model files saved**\n",
    "\n",
    "### Output Files:\n",
    "```\n",
    "models/\n",
    "|- weather_model_combined.pkl      (Hourly + Daily)\n",
    "|- weather_model_hourly.pkl\n",
    "|- weather_model_daily.pkl\n",
    "|- weather_model_hourly_regressor.pkl\n",
    "|- weather_model_hourly_classifier.pkl\n",
    "|- weather_model_daily_regressor.pkl\n",
    "|- weather_model_daily_classifier.pkl\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}