{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸŒ¤ï¸ Weather Model Training - Dual Model (Hourly + Daily)\n",
    "\n",
    "Notebook ini mengikuti panduan dari `training_guide.md` untuk melatih **dual-model**:\n",
    "1. **Model Hourly** - Prediksi per-jam (temp, humidity, windspeed, pressure, weather_code)\n",
    "2. **Model Daily** - Prediksi per-hari (temp_min, temp_max, temp_mean, humidity_avg, windspeed_avg, pressure_avg, weather_code_dominant)\n",
    "\n",
    "**Output:** 7 file model `.pkl` untuk berbagai kebutuhan deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Persiapan Lingkungan dan Pemuatan Pustaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies jika belum ada\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn xgboost joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    accuracy_score, f1_score, classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Classification Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    from xgboost import XGBRegressor, XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Skipping XGBoost models.\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "# Joblib for saving models\n",
    "import joblib\n",
    "\n",
    "print(\"âœ… Semua pustaka berhasil diimpor!\")\n",
    "print(f\"   - Pandas: {pd.__version__}\")\n",
    "print(f\"   - NumPy: {np.__version__}\")\n",
    "print(f\"   - XGBoost Available: {XGBOOST_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pengumpulan dan Pemuatan Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (23 kolom: hourly + daily features)\n",
    "DATA_PATH = '../data/historical_data_2000_2024.csv'\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Konversi timestamp ke datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Urutkan berdasarkan waktu (PENTING untuk time-series)\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"ğŸ“Š Dataset loaded: {len(df):,} baris x {len(df.columns)} kolom\")\n",
    "print(f\"ğŸ“… Rentang waktu: {df['timestamp'].min()} - {df['timestamp'].max()}\")\n",
    "print(f\"\\nğŸ“‹ Kolom dataset:\")\n",
    "print(df.columns.tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info struktur data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analisis Data Eksplorasi (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Statistik Deskriptif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistik deskriptif untuk fitur numerik\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualisasi Distribusi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi distribusi parameter cuaca utama (Hourly)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "params = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "titles = ['Temperature (Â°C)', 'Humidity (%)', 'Wind Speed (km/h)', 'Sea Level Pressure (hPa)']\n",
    "\n",
    "for ax, param, title in zip(axes.flatten(), params, titles):\n",
    "    sns.histplot(df[param], kde=True, ax=ax, color='steelblue')\n",
    "    ax.set_title(f'Distribusi {title}')\n",
    "    ax.set_xlabel(title)\n",
    "\n",
    "plt.suptitle('Distribusi Parameter Cuaca Hourly', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi distribusi parameter cuaca Daily\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "daily_params = ['temp_max_daily', 'temp_min_daily', 'temp_mean_daily', \n",
    "                'humidity_avg_daily', 'pressure_avg_daily', 'windspeed_avg_daily']\n",
    "titles = ['Temp Max (Â°C)', 'Temp Min (Â°C)', 'Temp Mean (Â°C)', \n",
    "          'Humidity Avg (%)', 'Pressure Avg (hPa)', 'Windspeed Avg (km/h)']\n",
    "\n",
    "for ax, param, title in zip(axes.flatten(), daily_params, titles):\n",
    "    sns.histplot(df[param].dropna(), kde=True, ax=ax, color='coral')\n",
    "    ax.set_title(f'Distribusi {title}')\n",
    "    ax.set_xlabel(title)\n",
    "\n",
    "plt.suptitle('Distribusi Parameter Cuaca Daily', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Analisis Korelasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap korelasi\n",
    "numeric_cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure', 'rain', \n",
    "                'weather_code', 'temp_max_daily', 'temp_min_daily', 'temp_mean_daily',\n",
    "                'humidity_avg_daily', 'pressure_avg_daily', 'windspeed_avg_daily']\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Heatmap Korelasi Antar Variabel Cuaca (Hourly + Daily)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Analisis Korelasi: weather_code dan rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis hubungan weather_code dengan rain\n",
    "weather_rain_analysis = df.groupby('weather_code')[['rain']].agg(['mean', 'min', 'max', 'count'])\n",
    "print(\"ğŸ“Š Weather Code vs Rain:\")\n",
    "weather_rain_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifikasi korelasi deterministik\n",
    "print(f\"\\nğŸ” Verifikasi rain == precipitation: {(df['rain'] == df['precipitation']).all()}\")\n",
    "print(f\"ğŸ” Weather codes dengan rain > 0: {sorted(df[df['rain'] > 0]['weather_code'].unique())}\")\n",
    "print(f\"ğŸ” Weather codes dengan rain = 0: {sorted(df[df['rain'] == 0]['weather_code'].unique())}\")\n",
    "\n",
    "# Kesimpulan\n",
    "print(\"\\nâœ… KESIMPULAN:\")\n",
    "print(\"   - rain dan precipitation IDENTIK di seluruh dataset\")\n",
    "print(\"   - weather_code >= 50 SELALU hujan (deterministik)\")\n",
    "print(\"   - Tidak perlu memprediksi rain terpisah, cukup prediksi weather_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pra-pemrosesan Data dan Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Preprocessing Data Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataframe untuk preprocessing\n",
    "df_hourly = df.copy()\n",
    "\n",
    "# 1. Label Encoding untuk 'conditions'\n",
    "le_conditions = LabelEncoder()\n",
    "df_hourly['conditions_encoded'] = le_conditions.fit_transform(df_hourly['conditions'])\n",
    "\n",
    "print(\"ğŸ“ Label Encoding untuk 'conditions':\")\n",
    "for i, label in enumerate(le_conditions.classes_):\n",
    "    print(f\"   {i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Engineering: Lag Features untuk Hourly\n",
    "hourly_target_cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "\n",
    "for col in hourly_target_cols:\n",
    "    # Lag 1 jam\n",
    "    df_hourly[f'{col}_lag_1'] = df_hourly[col].shift(1)\n",
    "    # Lag 24 jam\n",
    "    df_hourly[f'{col}_lag_24'] = df_hourly[col].shift(24)\n",
    "    # Rolling mean 24 jam\n",
    "    df_hourly[f'{col}_rolling_24'] = df_hourly[col].rolling(window=24).mean()\n",
    "\n",
    "print(f\"âœ… Feature Engineering Hourly selesai! Kolom baru: {12} fitur lag & rolling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Hapus baris dengan NaN (akibat lag & rolling)\n",
    "rows_before = len(df_hourly)\n",
    "df_hourly = df_hourly.dropna().reset_index(drop=True)\n",
    "rows_after = len(df_hourly)\n",
    "\n",
    "print(f\"ğŸ—‘ï¸ Baris dihapus (NaN): {rows_before - rows_after:,}\")\n",
    "print(f\"ğŸ“Š Dataset Hourly final: {rows_after:,} baris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Preprocessing Data Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregasi data hourly menjadi daily\n",
    "df_daily = df.groupby(['year', 'month', 'day']).agg({\n",
    "    'temp': ['min', 'max', 'mean'],\n",
    "    'humidity': 'mean',\n",
    "    'windspeed': 'mean',\n",
    "    'sealevelpressure': 'mean',\n",
    "    'weather_code': lambda x: x.mode()[0],  # Dominan weather_code\n",
    "    'rain': 'sum'  # Total curah hujan\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "df_daily.columns = ['year', 'month', 'day', \n",
    "                    'temp_min', 'temp_max', 'temp_mean',\n",
    "                    'humidity_avg', 'windspeed_avg', 'pressure_avg',\n",
    "                    'weather_code_dominant', 'rain_total']\n",
    "\n",
    "print(f\"ğŸ“Š Dataset Daily: {len(df_daily):,} baris (hari)\")\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering Daily - Lag Features\n",
    "df_daily['temp_min_lag_1'] = df_daily['temp_min'].shift(1)   # Kemarin\n",
    "df_daily['temp_max_lag_1'] = df_daily['temp_max'].shift(1)\n",
    "df_daily['temp_mean_lag_1'] = df_daily['temp_mean'].shift(1)\n",
    "df_daily['humidity_avg_lag_1'] = df_daily['humidity_avg'].shift(1)\n",
    "df_daily['windspeed_avg_lag_1'] = df_daily['windspeed_avg'].shift(1)\n",
    "df_daily['pressure_avg_lag_1'] = df_daily['pressure_avg'].shift(1)\n",
    "\n",
    "df_daily['temp_min_lag_7'] = df_daily['temp_min'].shift(7)   # Seminggu lalu\n",
    "df_daily['temp_max_lag_7'] = df_daily['temp_max'].shift(7)\n",
    "df_daily['temp_mean_lag_7'] = df_daily['temp_mean'].shift(7)\n",
    "df_daily['rain_total_lag_1'] = df_daily['rain_total'].shift(1)\n",
    "\n",
    "# Hapus NaN\n",
    "rows_before = len(df_daily)\n",
    "df_daily = df_daily.dropna().reset_index(drop=True)\n",
    "rows_after = len(df_daily)\n",
    "\n",
    "print(f\"ğŸ—‘ï¸ Baris dihapus (NaN): {rows_before - rows_after:,}\")\n",
    "print(f\"ğŸ“Š Dataset Daily final: {rows_after:,} baris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pelatihan dan Perbandingan Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Pemisahan Data (Time-Series Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== HOURLY DATA SPLIT =====\n",
    "hourly_train_size = int(len(df_hourly) * 0.8)\n",
    "hourly_train = df_hourly[:hourly_train_size]\n",
    "hourly_test = df_hourly[hourly_train_size:]\n",
    "\n",
    "print(f\"ğŸ“Š HOURLY Data Split (80-20):\")\n",
    "print(f\"   Train: {len(hourly_train):,} baris\")\n",
    "print(f\"   Test:  {len(hourly_test):,} baris\")\n",
    "\n",
    "# ===== DAILY DATA SPLIT =====\n",
    "daily_train_size = int(len(df_daily) * 0.8)\n",
    "daily_train = df_daily[:daily_train_size]\n",
    "daily_test = df_daily[daily_train_size:]\n",
    "\n",
    "print(f\"\\nğŸ“Š DAILY Data Split (80-20):\")\n",
    "print(f\"   Train: {len(daily_train):,} baris\")\n",
    "print(f\"   Test:  {len(daily_test):,} baris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== DEFINISI FITUR DAN TARGET =====\n",
    "\n",
    "# HOURLY Features\n",
    "hourly_feature_cols = [\n",
    "    'year', 'month', 'day', 'hour',\n",
    "    'temp_lag_1', 'temp_lag_24', 'temp_rolling_24',\n",
    "    'humidity_lag_1', 'humidity_lag_24', 'humidity_rolling_24',\n",
    "    'windspeed_lag_1', 'windspeed_lag_24', 'windspeed_rolling_24',\n",
    "    'sealevelpressure_lag_1', 'sealevelpressure_lag_24', 'sealevelpressure_rolling_24'\n",
    "]\n",
    "hourly_target_reg = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "hourly_target_clf = 'weather_code'\n",
    "\n",
    "# DAILY Features\n",
    "daily_feature_cols = [\n",
    "    'year', 'month', 'day',\n",
    "    'temp_min_lag_1', 'temp_max_lag_1', 'temp_mean_lag_1',\n",
    "    'humidity_avg_lag_1', 'windspeed_avg_lag_1', 'pressure_avg_lag_1',\n",
    "    'temp_min_lag_7', 'temp_max_lag_7', 'temp_mean_lag_7',\n",
    "    'rain_total_lag_1'\n",
    "]\n",
    "daily_target_reg = ['temp_min', 'temp_max', 'temp_mean', 'humidity_avg', 'windspeed_avg', 'pressure_avg']\n",
    "daily_target_clf = 'weather_code_dominant'\n",
    "\n",
    "# Pisahkan X dan y untuk HOURLY\n",
    "X_hourly_train = hourly_train[hourly_feature_cols]\n",
    "X_hourly_test = hourly_test[hourly_feature_cols]\n",
    "y_hourly_train_reg = hourly_train[hourly_target_reg]\n",
    "y_hourly_test_reg = hourly_test[hourly_target_reg]\n",
    "y_hourly_train_clf = hourly_train[hourly_target_clf]\n",
    "y_hourly_test_clf = hourly_test[hourly_target_clf]\n",
    "\n",
    "# Pisahkan X dan y untuk DAILY\n",
    "X_daily_train = daily_train[daily_feature_cols]\n",
    "X_daily_test = daily_test[daily_feature_cols]\n",
    "y_daily_train_reg = daily_train[daily_target_reg]\n",
    "y_daily_test_reg = daily_test[daily_target_reg]\n",
    "y_daily_train_clf = daily_train[daily_target_clf]\n",
    "y_daily_test_clf = daily_test[daily_target_clf]\n",
    "\n",
    "print(f\"âœ… HOURLY Features: {len(hourly_feature_cols)} | Targets Reg: {hourly_target_reg} | Target Clf: {hourly_target_clf}\")\n",
    "print(f\"âœ… DAILY Features: {len(daily_feature_cols)} | Targets Reg: {daily_target_reg} | Target Clf: {daily_target_clf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Komparasi Model Regresi (Hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisi model regresi\n",
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'K-Neighbors': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    regression_models['XGBoost'] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "# Fungsi evaluasi\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training HOURLY Regression Models\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”„ TRAINING HOURLY REGRESSION MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "hourly_reg_results = []\n",
    "\n",
    "for name, model in regression_models.items():\n",
    "    print(f\"\\nğŸ”„ Training {name}...\")\n",
    "    model.fit(X_hourly_train, y_hourly_train_reg)\n",
    "    y_pred = model.predict(X_hourly_test)\n",
    "    \n",
    "    overall_metrics = evaluate_regression(y_hourly_test_reg, y_pred)\n",
    "    overall_metrics['Model'] = name\n",
    "    hourly_reg_results.append(overall_metrics)\n",
    "    \n",
    "    print(f\"   âœ… {name} - RÂ²: {overall_metrics['R2']:.4f}, RMSE: {overall_metrics['RMSE']:.4f}\")\n",
    "\n",
    "df_hourly_reg = pd.DataFrame(hourly_reg_results).sort_values('R2', ascending=False)\n",
    "print(\"\\nğŸ“Š HASIL PERBANDINGAN REGRESI HOURLY:\")\n",
    "display(df_hourly_reg[['Model', 'R2', 'RMSE', 'MAE']].reset_index(drop=True))\n",
    "\n",
    "best_hourly_reg_model = df_hourly_reg.iloc[0]['Model']\n",
    "print(f\"\\nğŸ† MODEL TERBAIK REGRESI HOURLY: {best_hourly_reg_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Komparasi Model Klasifikasi (Hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisi model klasifikasi\n",
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "}\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    classification_models['XGBoost'] = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training HOURLY Classification Models\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”„ TRAINING HOURLY CLASSIFICATION MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "hourly_clf_results = []\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    print(f\"\\nğŸ”„ Training {name}...\")\n",
    "    model.fit(X_hourly_train, y_hourly_train_clf)\n",
    "    y_pred = model.predict(X_hourly_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_hourly_test_clf, y_pred)\n",
    "    f1_weighted = f1_score(y_hourly_test_clf, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    hourly_clf_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 (Weighted)': f1_weighted\n",
    "    })\n",
    "    \n",
    "    print(f\"   âœ… {name} - Accuracy: {accuracy:.4f}, F1: {f1_weighted:.4f}\")\n",
    "\n",
    "df_hourly_clf = pd.DataFrame(hourly_clf_results).sort_values('Accuracy', ascending=False)\n",
    "print(\"\\nğŸ“Š HASIL PERBANDINGAN KLASIFIKASI HOURLY:\")\n",
    "display(df_hourly_clf.reset_index(drop=True))\n",
    "\n",
    "best_hourly_clf_model = df_hourly_clf.iloc[0]['Model']\n",
    "print(f\"\\nğŸ† MODEL TERBAIK KLASIFIKASI HOURLY: {best_hourly_clf_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Komparasi Model Regresi (Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training DAILY Regression Models\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”„ TRAINING DAILY REGRESSION MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "daily_reg_results = []\n",
    "\n",
    "# Re-initialize models\n",
    "regression_models_daily = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'K-Neighbors': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    regression_models_daily['XGBoost'] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "for name, model in regression_models_daily.items():\n",
    "    print(f\"\\nğŸ”„ Training {name}...\")\n",
    "    model.fit(X_daily_train, y_daily_train_reg)\n",
    "    y_pred = model.predict(X_daily_test)\n",
    "    \n",
    "    overall_metrics = evaluate_regression(y_daily_test_reg, y_pred)\n",
    "    overall_metrics['Model'] = name\n",
    "    daily_reg_results.append(overall_metrics)\n",
    "    \n",
    "    print(f\"   âœ… {name} - RÂ²: {overall_metrics['R2']:.4f}, RMSE: {overall_metrics['RMSE']:.4f}\")\n",
    "\n",
    "df_daily_reg = pd.DataFrame(daily_reg_results).sort_values('R2', ascending=False)\n",
    "print(\"\\nğŸ“Š HASIL PERBANDINGAN REGRESI DAILY:\")\n",
    "display(df_daily_reg[['Model', 'R2', 'RMSE', 'MAE']].reset_index(drop=True))\n",
    "\n",
    "best_daily_reg_model = df_daily_reg.iloc[0]['Model']\n",
    "print(f\"\\nğŸ† MODEL TERBAIK REGRESI DAILY: {best_daily_reg_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Komparasi Model Klasifikasi (Daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training DAILY Classification Models\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ”„ TRAINING DAILY CLASSIFICATION MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "daily_clf_results = []\n",
    "\n",
    "# Re-initialize models\n",
    "classification_models_daily = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    classification_models_daily['XGBoost'] = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "for name, model in classification_models_daily.items():\n",
    "    print(f\"\\nğŸ”„ Training {name}...\")\n",
    "    model.fit(X_daily_train, y_daily_train_clf)\n",
    "    y_pred = model.predict(X_daily_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_daily_test_clf, y_pred)\n",
    "    f1_weighted = f1_score(y_daily_test_clf, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    daily_clf_results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy,\n",
    "        'F1 (Weighted)': f1_weighted\n",
    "    })\n",
    "    \n",
    "    print(f\"   âœ… {name} - Accuracy: {accuracy:.4f}, F1: {f1_weighted:.4f}\")\n",
    "\n",
    "df_daily_clf = pd.DataFrame(daily_clf_results).sort_values('Accuracy', ascending=False)\n",
    "print(\"\\nğŸ“Š HASIL PERBANDINGAN KLASIFIKASI DAILY:\")\n",
    "display(df_daily_clf.reset_index(drop=True))\n",
    "\n",
    "best_daily_clf_model = df_daily_clf.iloc[0]['Model']\n",
    "print(f\"\\nğŸ† MODEL TERBAIK KLASIFIKASI DAILY: {best_daily_clf_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Kesimpulan Pemilihan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ğŸ¯ KESIMPULAN PEMILIHAN MODEL TERBAIK\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“ˆ MODEL HOURLY:\")\n",
    "print(f\"   ğŸ† Regresi: {best_hourly_reg_model} (RÂ²: {df_hourly_reg.iloc[0]['R2']:.4f})\")\n",
    "print(f\"   ğŸ† Klasifikasi: {best_hourly_clf_model} (Acc: {df_hourly_clf.iloc[0]['Accuracy']:.4f})\")\n",
    "\n",
    "print(\"\\nğŸ“Š MODEL DAILY:\")\n",
    "print(f\"   ğŸ† Regresi: {best_daily_reg_model} (RÂ²: {df_daily_reg.iloc[0]['R2']:.4f})\")\n",
    "print(f\"   ğŸ† Klasifikasi: {best_daily_clf_model} (Acc: {df_daily_clf.iloc[0]['Accuracy']:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Langkah selanjutnya: Retraining dengan 100% data, lalu simpan 7 file model\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retraining dengan 100% Data dan Penyimpanan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabung train + test untuk final training\n",
    "X_hourly_full = df_hourly[hourly_feature_cols]\n",
    "y_hourly_reg_full = df_hourly[hourly_target_reg]\n",
    "y_hourly_clf_full = df_hourly[hourly_target_clf]\n",
    "\n",
    "X_daily_full = df_daily[daily_feature_cols]\n",
    "y_daily_reg_full = df_daily[daily_target_reg]\n",
    "y_daily_clf_full = df_daily[daily_target_clf]\n",
    "\n",
    "print(f\"ğŸ“Š Full Hourly Data: {len(X_hourly_full):,} baris\")\n",
    "print(f\"ğŸ“Š Full Daily Data: {len(X_daily_full):,} baris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Training - Hourly Models (menggunakan Random Forest sebagai default)\n",
    "print(\"ğŸ”„ Training Final Models...\\n\")\n",
    "\n",
    "# HOURLY\n",
    "hourly_regressor = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "hourly_regressor.fit(X_hourly_full, y_hourly_reg_full)\n",
    "print(\"âœ… Hourly Regressor trained\")\n",
    "\n",
    "hourly_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "hourly_classifier.fit(X_hourly_full, y_hourly_clf_full)\n",
    "print(\"âœ… Hourly Classifier trained\")\n",
    "\n",
    "# DAILY\n",
    "daily_regressor = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "daily_regressor.fit(X_daily_full, y_daily_reg_full)\n",
    "print(\"âœ… Daily Regressor trained\")\n",
    "\n",
    "daily_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "daily_classifier.fit(X_daily_full, y_daily_clf_full)\n",
    "print(\"âœ… Daily Classifier trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "weather_code_to_rain = {0:0, 1:0, 2:0, 3:0, 51:0.2, 53:0.7, 55:1.1, 61:1.7, 63:4.0, 65:10.3}\n",
    "\n",
    "# ===== PACKAGE DEFINITIONS =====\n",
    "\n",
    "# 1. Combined Package\n",
    "combined_package = {\n",
    "    'hourly': {\n",
    "        'regressor': hourly_regressor,\n",
    "        'classifier': hourly_classifier,\n",
    "        'feature_columns': hourly_feature_cols,\n",
    "        'target_regression': hourly_target_reg,\n",
    "        'target_classification': hourly_target_clf,\n",
    "    },\n",
    "    'daily': {\n",
    "        'regressor': daily_regressor,\n",
    "        'classifier': daily_classifier,\n",
    "        'feature_columns': daily_feature_cols,\n",
    "        'target_regression': daily_target_reg,\n",
    "        'target_classification': daily_target_clf,\n",
    "    },\n",
    "    'label_encoder': le_conditions,\n",
    "    'weather_code_to_rain': weather_code_to_rain,\n",
    "    'version': '2.1',\n",
    "    'trained_date': datetime.now().isoformat(),\n",
    "    'model_type': 'combined'\n",
    "}\n",
    "\n",
    "# 2. Hourly Package\n",
    "hourly_package = {\n",
    "    'regressor': hourly_regressor,\n",
    "    'classifier': hourly_classifier,\n",
    "    'feature_columns': hourly_feature_cols,\n",
    "    'target_regression': hourly_target_reg,\n",
    "    'target_classification': hourly_target_clf,\n",
    "    'label_encoder': le_conditions,\n",
    "    'weather_code_to_rain': weather_code_to_rain,\n",
    "    'version': '2.1',\n",
    "    'trained_date': datetime.now().isoformat(),\n",
    "    'model_type': 'hourly'\n",
    "}\n",
    "\n",
    "# 3. Daily Package\n",
    "daily_package = {\n",
    "    'regressor': daily_regressor,\n",
    "    'classifier': daily_classifier,\n",
    "    'feature_columns': daily_feature_cols,\n",
    "    'target_regression': daily_target_reg,\n",
    "    'target_classification': daily_target_clf,\n",
    "    'label_encoder': le_conditions,\n",
    "    'weather_code_to_rain': weather_code_to_rain,\n",
    "    'version': '2.1',\n",
    "    'trained_date': datetime.now().isoformat(),\n",
    "    'model_type': 'daily'\n",
    "}\n",
    "\n",
    "# 4-7. Individual Packages\n",
    "hourly_reg_package = {\n",
    "    'model': hourly_regressor,\n",
    "    'feature_columns': hourly_feature_cols,\n",
    "    'target': hourly_target_reg,\n",
    "    'version': '2.1',\n",
    "    'model_type': 'hourly_regressor'\n",
    "}\n",
    "\n",
    "hourly_clf_package = {\n",
    "    'model': hourly_classifier,\n",
    "    'feature_columns': hourly_feature_cols,\n",
    "    'target': hourly_target_clf,\n",
    "    'label_encoder': le_conditions,\n",
    "    'weather_code_to_rain': weather_code_to_rain,\n",
    "    'version': '2.1',\n",
    "    'model_type': 'hourly_classifier'\n",
    "}\n",
    "\n",
    "daily_reg_package = {\n",
    "    'model': daily_regressor,\n",
    "    'feature_columns': daily_feature_cols,\n",
    "    'target': daily_target_reg,\n",
    "    'version': '2.1',\n",
    "    'model_type': 'daily_regressor'\n",
    "}\n",
    "\n",
    "daily_clf_package = {\n",
    "    'model': daily_classifier,\n",
    "    'feature_columns': daily_feature_cols,\n",
    "    'target': daily_target_clf,\n",
    "    'label_encoder': le_conditions,\n",
    "    'weather_code_to_rain': weather_code_to_rain,\n",
    "    'version': '2.1',\n",
    "    'model_type': 'daily_classifier'\n",
    "}\n",
    "\n",
    "print(\"âœ… All model packages created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan 7 file model\n",
    "MODEL_DIR = 'models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# 1-3: Main packages\n",
    "joblib.dump(combined_package, f'{MODEL_DIR}/weather_model_combined.pkl')\n",
    "print(\"âœ… weather_model_combined.pkl saved\")\n",
    "\n",
    "joblib.dump(hourly_package, f'{MODEL_DIR}/weather_model_hourly.pkl')\n",
    "print(\"âœ… weather_model_hourly.pkl saved\")\n",
    "\n",
    "joblib.dump(daily_package, f'{MODEL_DIR}/weather_model_daily.pkl')\n",
    "print(\"âœ… weather_model_daily.pkl saved\")\n",
    "\n",
    "# 4-7: Individual packages\n",
    "joblib.dump(hourly_reg_package, f'{MODEL_DIR}/weather_model_hourly_regressor.pkl')\n",
    "print(\"âœ… weather_model_hourly_regressor.pkl saved\")\n",
    "\n",
    "joblib.dump(hourly_clf_package, f'{MODEL_DIR}/weather_model_hourly_classifier.pkl')\n",
    "print(\"âœ… weather_model_hourly_classifier.pkl saved\")\n",
    "\n",
    "joblib.dump(daily_reg_package, f'{MODEL_DIR}/weather_model_daily_regressor.pkl')\n",
    "print(\"âœ… weather_model_daily_regressor.pkl saved\")\n",
    "\n",
    "joblib.dump(daily_clf_package, f'{MODEL_DIR}/weather_model_daily_classifier.pkl')\n",
    "print(\"âœ… weather_model_daily_classifier.pkl saved\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Total: 7 model files saved to {MODEL_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rangkuman\n",
    "\n",
    "Notebook ini telah menyelesaikan:\n",
    "\n",
    "1. âœ… **Persiapan Lingkungan** - Import semua pustaka\n",
    "2. âœ… **Pemuatan Data** - Load dataset 23 kolom (hourly + daily features)\n",
    "3. âœ… **EDA** - Analisis distribusi, korelasi, hubungan weather_code dengan rain\n",
    "4. âœ… **Feature Engineering** - Lag features untuk Hourly dan Daily\n",
    "5. âœ… **Perbandingan Model** - 5 model regresi & 4 model klasifikasi untuk Hourly dan Daily\n",
    "6. âœ… **Retraining & Penyimpanan** - 7 file model `.pkl` tersimpan\n",
    "\n",
    "**Output Files:**\n",
    "```\n",
    "models/\n",
    "â”œâ”€â”€ weather_model_combined.pkl           # Hourly + Daily\n",
    "â”œâ”€â”€ weather_model_hourly.pkl             # Hourly only\n",
    "â”œâ”€â”€ weather_model_daily.pkl              # Daily only\n",
    "â”œâ”€â”€ weather_model_hourly_regressor.pkl   # Hourly Reg only\n",
    "â”œâ”€â”€ weather_model_hourly_classifier.pkl  # Hourly Clf only\n",
    "â”œâ”€â”€ weather_model_daily_regressor.pkl    # Daily Reg only\n",
    "â””â”€â”€ weather_model_daily_classifier.pkl   # Daily Clf only\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
