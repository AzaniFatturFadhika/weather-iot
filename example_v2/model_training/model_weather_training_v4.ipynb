{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f62ff810",
   "metadata": {},
   "source": [
    "# Weather Model Training v4.0 - Date-Based Seasonality Model\n",
    "    \n",
    "Implementasi **Date-Based Seasonality Model** sesuai `training_guide_v4.md`.\n",
    "    \n",
    "## Karakteristik v4.0:\n",
    "*   **Input:** HANYA komponen waktu (`day`, `month`, `year`, `hour`).\n",
    "*   **Tanpa Sensor Input:** Tidak membutuhkan data suhu/kelembaban masa lalu untuk prediksi.\n",
    "*   **Strategi:** Direct Mapping (Tanggal -> Cuaca), cocok untuk forecasting jangka panjang.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Persiapan Lingkungan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor, XGBClassifier\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "import joblib\n",
    "print(f\"Libraries loaded | XGBoost: {XGBOOST_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/historical_data_2000_2024.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "print(f\"Dataset: {len(df):,} rows x {len(df.columns)} cols\")\n",
    "print(f\"Range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Statistik Deskriptif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Distribusi Parameter Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "params = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "titles = ['Temperature (C)', 'Humidity (%)', 'Wind Speed (km/h)', 'Pressure (hPa)']\n",
    "for ax, param, title in zip(axes.flatten(), params, titles):\n",
    "    sns.histplot(df[param], kde=True, ax=ax, color='steelblue')\n",
    "    ax.set_title(f'Distribusi {title}')\n",
    "plt.suptitle('Distribusi Parameter Cuaca Hourly', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Korelasi Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure', 'rain', 'weather_code']\n",
    "sns.heatmap(df[cols].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Weather Code vs Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('weather_code')[['rain']].agg(['mean', 'count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = df.copy()\n",
    "le_conditions = LabelEncoder()\n",
    "df_hourly['conditions_encoded'] = le_conditions.fit_transform(df_hourly['conditions'])\n",
    "le_weather_code = LabelEncoder()\n",
    "df_hourly['weather_code_encoded'] = le_weather_code.fit_transform(df_hourly['weather_code'])\n",
    "print(\"Label encoding done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 [v2.0] Cyclical Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v4.0] Cyclical features REMOVED\n",
    "print('Cyclical features skipped for v4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Lag Features Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v4.0] Lag/Rolling features REMOVED\n",
    "df_hourly = df_hourly.dropna().reset_index(drop=True)\n",
    "print(f'Hourly: {len(df_hourly):,} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 [v2.0] Preprocessing Data Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregasi hourly ke daily\n",
    "df_daily = df.groupby(['year', 'month', 'day']).agg({\n",
    "    'temp': ['min', 'max', 'mean'],\n",
    "    'humidity': 'mean',\n",
    "    'windspeed': 'mean',\n",
    "    'sealevelpressure': 'mean',\n",
    "    'weather_code': lambda x: x.mode()[0],\n",
    "    'rain': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "df_daily.columns = ['year', 'month', 'day', 'temp_min', 'temp_max', 'temp_mean',\n",
    "                    'humidity_avg', 'windspeed_avg', 'pressure_avg',\n",
    "                    'weather_code_dominant', 'rain_total']\n",
    "\n",
    "le_weather_code_daily = LabelEncoder()\n",
    "df_daily['weather_code_dominant_encoded'] = le_weather_code_daily.fit_transform(df_daily['weather_code_dominant'])\n",
    "print(f\"Daily: {len(df_daily):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 [v2.0] Lag Features Daily dengan Rolling 3d/7d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v4.0] Daily Lag/Rolling features REMOVED\n",
    "df_daily = df_daily.dropna().reset_index(drop=True)\n",
    "print(f'Daily after features: {len(df_daily):,} rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 [v2.0] Expanding Window Cross-Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "def evaluate_with_cv(model, X, y):\n",
    "    \"\"\"Evaluasi dengan Time Series Cross-Validation\"\"\"\n",
    "    scores = {'r2': [], 'rmse': []}\n",
    "    for train_idx, test_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        scores['r2'].append(r2_score(y_test, y_pred))\n",
    "        scores['rmse'].append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    return {'R2_mean': np.mean(scores['r2']), 'R2_std': np.std(scores['r2']), 'RMSE_mean': np.mean(scores['rmse'])}\n",
    "\n",
    "print(\"CV function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Data Split (HOURLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v4.0] DATE-BASED FEATURES ONLY\n",
    "hourly_feature_cols = ['day', 'month', 'year', 'hour']\n",
    "daily_feature_cols = ['day', 'month', 'year']\n",
    "\n",
    "# Target tetap sama\n",
    "hourly_target_reg = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "hourly_target_clf = 'conditions_encoded'\n",
    "\n",
    "daily_target_reg = ['temp_min', 'temp_max', 'temp_mean', 'humidity_avg', 'windspeed_avg', 'pressure_avg']\n",
    "daily_target_clf = 'conditions_dominant_encoded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Data Split (DAILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v4.0] Features Daily - DATE ONLY\n",
    "daily_feature_cols = ['day', 'month', 'year']\n",
    "\n",
    "daily_target_reg = ['temp_min', 'temp_max', 'temp_mean', 'humidity_avg', 'windspeed_avg', 'pressure_avg']\n",
    "daily_target_clf = 'weather_code_dominant_encoded'\n",
    "\n",
    "daily_train_size = int(len(df_daily) * 0.8)\n",
    "daily_train = df_daily[:daily_train_size]\n",
    "daily_test = df_daily[daily_train_size:]\n",
    "\n",
    "X_daily_train = daily_train[daily_feature_cols]\n",
    "X_daily_test = daily_test[daily_feature_cols]\n",
    "y_daily_train_reg = daily_train[daily_target_reg]\n",
    "y_daily_test_reg = daily_test[daily_target_reg]\n",
    "y_daily_train_clf = daily_train[daily_target_clf]\n",
    "y_daily_test_clf = daily_test[daily_target_clf]\n",
    "\n",
    "print(f\"Daily Train: {len(X_daily_train):,} | Test: {len(X_daily_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Regression Models (HOURLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest Regressor': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    regression_models['XGBoost Regressor'] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "def evaluate_regression(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return {'MSE': mse, 'RMSE': np.sqrt(mse), 'MAE': mean_absolute_error(y_true, y_pred), 'R2': r2_score(y_true, y_pred)}\n",
    "\n",
    "reg_results = []\n",
    "for name, model in regression_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_hourly_train, y_hourly_train_reg)\n",
    "    y_pred = model.predict(X_hourly_test)\n",
    "    metrics = evaluate_regression(y_hourly_test_reg, y_pred)\n",
    "    metrics['Model'] = name\n",
    "    reg_results.append(metrics)\n",
    "\n",
    "df_hourly_reg = pd.DataFrame(reg_results).sort_values('R2', ascending=False)\n",
    "display(df_hourly_reg[['Model', 'R2', 'RMSE', 'MAE']])\n",
    "best_hourly_reg_name = df_hourly_reg.iloc[0]['Model']\n",
    "print(f\"Best Hourly Regression: {best_hourly_reg_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 [v2.0] Classification with Class Balancing (HOURLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    classification_models['XGBoost Classifier'] = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "clf_results = []\n",
    "for name, model in classification_models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_hourly_train, y_hourly_train_clf)\n",
    "    y_pred = model.predict(X_hourly_test)\n",
    "    clf_results.append({'Model': name, 'Accuracy': accuracy_score(y_hourly_test_clf, y_pred), \n",
    "                        'F1': f1_score(y_hourly_test_clf, y_pred, average='weighted', zero_division=0)})\n",
    "\n",
    "df_hourly_clf = pd.DataFrame(clf_results).sort_values('Accuracy', ascending=False)\n",
    "display(df_hourly_clf)\n",
    "best_hourly_clf_name = df_hourly_clf.iloc[0]['Model']\n",
    "print(f\"Best Hourly Classification: {best_hourly_clf_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Regression Models (DAILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initialize models\n",
    "daily_reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'K-Neighbors Regressor': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(random_state=42, max_depth=10),\n",
    "    'Random Forest Regressor': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    daily_reg_models['XGBoost Regressor'] = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "daily_reg_results = []\n",
    "for name, model in daily_reg_models.items():\n",
    "    print(f\"Training Daily {name}...\")\n",
    "    model.fit(X_daily_train, y_daily_train_reg)\n",
    "    y_pred = model.predict(X_daily_test)\n",
    "    metrics = evaluate_regression(y_daily_test_reg, y_pred)\n",
    "    metrics['Model'] = name\n",
    "    daily_reg_results.append(metrics)\n",
    "\n",
    "df_daily_reg = pd.DataFrame(daily_reg_results).sort_values('R2', ascending=False)\n",
    "display(df_daily_reg[['Model', 'R2', 'RMSE', 'MAE']])\n",
    "best_daily_reg_name = df_daily_reg.iloc[0]['Model']\n",
    "print(f\"Best Daily Regression: {best_daily_reg_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Classification (DAILY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_clf_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1),\n",
    "}\n",
    "if XGBOOST_AVAILABLE:\n",
    "    daily_clf_models['XGBoost Classifier'] = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "daily_clf_results = []\n",
    "for name, model in daily_clf_models.items():\n",
    "    print(f\"Training Daily {name}...\")\n",
    "    model.fit(X_daily_train, y_daily_train_clf)\n",
    "    y_pred = model.predict(X_daily_test)\n",
    "    daily_clf_results.append({'Model': name, 'Accuracy': accuracy_score(y_daily_test_clf, y_pred),\n",
    "                              'F1': f1_score(y_daily_test_clf, y_pred, average='weighted', zero_division=0)})\n",
    "\n",
    "df_daily_clf = pd.DataFrame(daily_clf_results).sort_values('Accuracy', ascending=False)\n",
    "display(df_daily_clf)\n",
    "print(f\"Best Daily Classification: {df_daily_clf.iloc[0]['Model']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analisis Kinerja Individual Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best models Regression\n",
    "best_reg_model = LinearRegression()\n",
    "best_reg_model.fit(X_hourly_train, y_hourly_train_reg)\n",
    "\n",
    "# Per-parameter evaluation\n",
    "y_pred = best_reg_model.predict(X_hourly_test)\n",
    "param_results = []\n",
    "for i, param in enumerate(hourly_target_reg):\n",
    "    mae = mean_absolute_error(y_hourly_test_reg.iloc[:, i], y_pred[:, i])\n",
    "    rmse = np.sqrt(mean_squared_error(y_hourly_test_reg.iloc[:, i], y_pred[:, i]))\n",
    "    r2 = r2_score(y_hourly_test_reg.iloc[:, i], y_pred[:, i])\n",
    "    param_results.append({'Parameter': param, 'MAE': round(mae, 4), 'RMSE': round(rmse, 4), 'R2': round(r2, 4)})\n",
    "\n",
    "display(pd.DataFrame(param_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Train best models Classification\n",
    "best_clf_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "best_clf_model.fit(X_hourly_train, y_hourly_train_clf)\n",
    "\n",
    "y_pred_clf = best_clf_model.predict(X_hourly_test)\n",
    "y_pred_proba_clf = best_clf_model.predict_proba(X_hourly_test)\n",
    "\n",
    "clf_accuracy = accuracy_score(y_hourly_test_clf, y_pred_clf)\n",
    "clf_precision = precision_score(y_hourly_test_clf, y_pred_clf, average='weighted')\n",
    "clf_recall = recall_score(y_hourly_test_clf, y_pred_clf, average='weighted')\n",
    "clf_f1 = f1_score(y_hourly_test_clf, y_pred_clf, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classification Accuracy: {clf_accuracy:.4f}\")\n",
    "print(f\"Classification Precision (weighted): {clf_precision:.4f}\")\n",
    "print(f\"Classification Recall (weighted): {clf_recall:.4f}\")\n",
    "print(f\"Classification F1-Score (weighted): {clf_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_hourly_test_clf, y_pred_clf))\n",
    "\n",
    "# Optional: Plot Confusion Matrix\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_hourly_test_clf, y_pred_clf, labels=best_clf_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_clf_model.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\".0f\", ax=ax)\n",
    "plt.title('Confusion Matrix for Classification Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Visualisasi Januari 2022 (Gap 2 Hari)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_mask = (df_hourly['year'] == 2022) & (df_hourly['month'] == 1)\n",
    "df_jan = df_hourly[jan_mask].copy()\n",
    "\n",
    "if len(df_jan) > 0:\n",
    "    X_jan = df_jan[hourly_feature_cols]\n",
    "    y_jan_pred = best_reg_model.predict(X_jan)\n",
    "    df_jan['temp_pred'] = y_jan_pred[:, 0]\n",
    "    df_jan['humidity_pred'] = y_jan_pred[:, 1]\n",
    "    df_jan['windspeed_pred'] = y_jan_pred[:, 2]\n",
    "    df_jan['pressure_pred'] = y_jan_pred[:, 3]\n",
    "    \n",
    "    df_jan_daily = df_jan.set_index('timestamp').resample('D').mean(numeric_only=True).reset_index()\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 16))\n",
    "    params = [('temp', 'temp_pred', 'Temperature (C)', 'red'),\n",
    "              ('humidity', 'humidity_pred', 'Humidity (%)', 'blue'),\n",
    "              ('windspeed', 'windspeed_pred', 'Wind Speed (km/h)', 'green'),\n",
    "              ('sealevelpressure', 'pressure_pred', 'Pressure (hPa)', 'purple')]\n",
    "    \n",
    "    for ax, (actual, pred, title, color) in zip(axes, params):\n",
    "        ax.plot(df_jan_daily['timestamp'], df_jan_daily[actual], '-o', color=color, label='Actual', linewidth=2)\n",
    "        ax.plot(df_jan_daily['timestamp'], df_jan_daily[pred], '--s', color=color, alpha=0.6, label='Predicted', linewidth=2)\n",
    "        ax.set_title(f'{title} - January 2022 (Daily Data)')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('outputs/jan_2022_predictions_v4.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No data for January 2022')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_jan) > 0:\n",
    "    y_jan_clf_pred = best_clf_model.predict(X_jan)\n",
    "    cm = confusion_matrix(df_jan['weather_code_encoded'], y_jan_clf_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=le_weather_code.classes_, yticklabels=le_weather_code.classes_)\n",
    "    plt.title('Confusion Matrix - January 2022')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.savefig('outputs/jan_2022_confusion_v4.png', dpi=150)\n",
    "    plt.show()\n",
    "    print(classification_report(df_jan['weather_code_encoded'], y_jan_clf_pred, target_names=[str(c) for c in le_weather_code.classes_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Retraining with 100% Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOURLY MODELS\n",
    "X_hourly_full = df_hourly[hourly_feature_cols]\n",
    "y_hourly_reg_full = df_hourly[hourly_target_reg]\n",
    "y_hourly_clf_full = df_hourly[hourly_target_clf]\n",
    "\n",
    "print('Training final hourly models...')\n",
    "hourly_regressor = LinearRegression()\n",
    "hourly_regressor.fit(X_hourly_full, y_hourly_reg_full)\n",
    "\n",
    "hourly_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "hourly_classifier.fit(X_hourly_full, y_hourly_clf_full)\n",
    "\n",
    "# DAILY MODELS\n",
    "X_daily_full = df_daily[daily_feature_cols]\n",
    "y_daily_reg_full = df_daily[daily_target_reg]\n",
    "y_daily_clf_full = df_daily[daily_target_clf]\n",
    "\n",
    "print('Training final daily models...')\n",
    "daily_regressor = LinearRegression()\n",
    "daily_regressor.fit(X_daily_full, y_daily_reg_full)\n",
    "\n",
    "daily_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "daily_classifier.fit(X_daily_full, y_daily_clf_full)\n",
    "\n",
    "print('All 4 final models trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Models (7 Files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "weather_code_to_rain = {0:0, 1:0, 2:0, 3:0, 51:0.2, 53:0.7, 55:1.1, 61:1.7, 63:4.0, 65:10.3}\n",
    "\n",
    "# 1. COMBINED MODEL\n",
    "combined_package = {\n",
    "    'hourly': {\n",
    "        'regressor': hourly_regressor,\n",
    "        'classifier': hourly_classifier,\n",
    "        'feature_columns': ['day', 'month', 'year', 'hour'],\n",
    "        'target_regression': hourly_target_reg,\n",
    "        'target_classification': 'weather_code',\n",
    "    },\n",
    "    'daily': {\n",
    "        'regressor': daily_regressor,\n",
    "        'classifier': daily_classifier,\n",
    "        'feature_columns': ['day', 'month', 'year'],\n",
    "        'target_regression': daily_target_reg,\n",
    "        'target_classification': 'weather_code_dominant',\n",
    "    },\n",
    "    'label_encoder_hourly': le_weather_code,\n",
    "    'label_encoder_daily': le_weather_code_daily,\n",
    "    'label_encoder_conditions': le_conditions,\n",
    "    'weather_code_to_rain': weather_code_to_rain,\n",
    "    \n",
    "    \n",
    "    'version': '4.0',\n",
    "    'trained_date': datetime.now().isoformat(),\n",
    "}\n",
    "joblib.dump(combined_package, 'models/v4_weather_model_combined.pkl')\n",
    "print('1. Combined model saved')\n",
    "\n",
    "# 2. HOURLY MODEL\n",
    "hourly_package = {\n",
    "    'regressor': hourly_regressor, 'classifier': hourly_classifier,\n",
    "    'feature_columns': ['day', 'month', 'year', 'hour'], 'target_regression': hourly_target_reg,\n",
    "    'label_encoder': le_weather_code, 'weather_code_to_rain': weather_code_to_rain, 'version': '4.0'\n",
    "}\n",
    "joblib.dump(hourly_package, 'models/v4_weather_model_hourly.pkl')\n",
    "print('2. Hourly model saved')\n",
    "\n",
    "# 3. DAILY MODEL\n",
    "daily_package = {\n",
    "    'regressor': daily_regressor, 'classifier': daily_classifier,\n",
    "    'feature_columns': ['day', 'month', 'year'], 'target_regression': daily_target_reg,\n",
    "    'label_encoder': le_weather_code_daily, 'weather_code_to_rain': weather_code_to_rain, 'version': '4.0'\n",
    "}\n",
    "joblib.dump(daily_package, 'models/v4_weather_model_daily.pkl')\n",
    "print('3. Daily model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-7. SEPARATE FILES\n",
    "joblib.dump({'model': hourly_regressor, 'features': hourly_feature_cols, 'target': hourly_target_reg}, \n",
    "            'models/v4_weather_model_hourly_regressor.pkl')\n",
    "print('4. Hourly regressor saved')\n",
    "\n",
    "joblib.dump({'model': hourly_classifier, 'features': hourly_feature_cols, 'label_encoder': le_weather_code}, \n",
    "            'models/v4_weather_model_hourly_classifier.pkl')\n",
    "print('5. Hourly classifier saved')\n",
    "\n",
    "joblib.dump({'model': daily_regressor, 'features': daily_feature_cols, 'target': daily_target_reg}, \n",
    "            'models/v4_weather_model_daily_regressor.pkl')\n",
    "print('6. Daily regressor saved')\n",
    "\n",
    "joblib.dump({'model': daily_classifier, 'features': daily_feature_cols, 'label_encoder': le_weather_code_daily}, \n",
    "            'models/v4_weather_model_daily_classifier.pkl')\n",
    "print('7. Daily classifier saved')\n",
    "\n",
    "print('\\n7 model files saved to models/ folder!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multi-Step Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_weather_v4(model_reg, model_clf, start_date, n_hours=24):\n",
    "    future_dates = [start_date + pd.Timedelta(hours=i) for i in range(n_hours)]\n",
    "    \n",
    "    # Buat DataFrame Input (HANYA WAKTU)\n",
    "    features = pd.DataFrame({\n",
    "        'day': [d.day for d in future_dates],\n",
    "        'month': [d.month for d in future_dates],\n",
    "        'year': [d.year for d in future_dates],\n",
    "        'hour': [d.hour for d in future_dates]\n",
    "    })\n",
    "    \n",
    "    # Predict\n",
    "    reg_pred = model_reg.predict(features)\n",
    "    clf_pred = model_clf.predict(features)\n",
    "    \n",
    "    # Format Output\n",
    "    results = []\n",
    "    for i, date in enumerate(future_dates):\n",
    "        results.append({\n",
    "            'timestamp': date,\n",
    "            'temp': reg_pred[i][0],\n",
    "            'humidity': reg_pred[i][1],\n",
    "            'windspeed': reg_pred[i][2],\n",
    "            'sealevelpressure': reg_pred[i][3],\n",
    "            'conditions': clf_pred[i]\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v4.0] Visualization using Direct Forecast\n",
    "# Load trained models from current session (or v4 file)\n",
    "loaded_reg_model = hourly_regressor\n",
    "loaded_clf_model = hourly_classifier\n",
    "\n",
    "# Generate forecast for last 72 hours of test set\n",
    "start_date = hourly_test['timestamp'].iloc[-72]\n",
    "forecast = predict_future_weather_v4(loaded_reg_model, loaded_clf_model, start_date, n_hours=72)\n",
    "\n",
    "actual_72h = hourly_test.tail(72).reset_index(drop=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "params = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "actual_cols = ['temp', 'humidity', 'windspeed', 'sealevelpressure']\n",
    "\n",
    "for ax, param, actual_col in zip(axes.flatten(), params, actual_cols):\n",
    "    ax.plot(range(72), actual_72h[actual_col].values, 'b-', label='Actual', linewidth=2)\n",
    "    ax.plot(range(72), forecast[param].values, 'r--', label='Forecast (v4)', linewidth=2)\n",
    "    ax.set_title(f'{param} - 72h Direct Forecast (Date-Based)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/direct_forecast_72h_v4.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Incremental Learning Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "r2_scores = []\n",
    "\n",
    "for frac in fractions:\n",
    "    n = int(len(X_hourly_train) * frac)\n",
    "    temp_model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    temp_model.fit(X_hourly_train.iloc[:n], y_hourly_train_reg.iloc[:n])\n",
    "    r2 = r2_score(y_hourly_test_reg, temp_model.predict(X_hourly_test))\n",
    "    r2_scores.append(r2)\n",
    "    print(f'{int(frac*100):3d}%: R2 = {r2:.4f}')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([f*100 for f in fractions], r2_scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('% of Training Data')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('Impact of Incremental Data on Model Performance')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('outputs/incremental_learning.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Completed:\n",
    "1. Cyclical time features (Sin/Cos)\n",
    "2. Interaction features (Dew Point, Temp Range)\n",
    "3. Class balancing (`class_weight='balanced'`)\n",
    "4. Expanding Window CV function\n",
    "5. Daily model preprocessing + training\n",
    "6. January 2022 visualization (2-day gap)\n",
    "7. Multi-step recursive forecasting\n",
    "8. **7 model files saved**\n",
    "\n",
    "### Output Files:\n",
    "```\n",
    "models/\n",
    "|- weather_model_combined.pkl      (Hourly + Daily)\n",
    "|- weather_model_hourly.pkl\n",
    "|- weather_model_daily.pkl\n",
    "|- weather_model_hourly_regressor.pkl\n",
    "|- weather_model_hourly_classifier.pkl\n",
    "|- weather_model_daily_regressor.pkl\n",
    "|- weather_model_daily_classifier.pkl\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
