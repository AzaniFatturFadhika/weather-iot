{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88ff194e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/26] Fetching data for 2000 (2000-01-01 to 2000-12-31)...\n",
      "   ‚úÖ 8,784 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[2/26] Fetching data for 2001 (2001-01-01 to 2001-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[3/26] Fetching data for 2002 (2002-01-01 to 2002-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[4/26] Fetching data for 2003 (2003-01-01 to 2003-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[5/26] Fetching data for 2004 (2004-01-01 to 2004-12-31)...\n",
      "   ‚úÖ 8,784 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[6/26] Fetching data for 2005 (2005-01-01 to 2005-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[7/26] Fetching data for 2006 (2006-01-01 to 2006-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[8/26] Fetching data for 2007 (2007-01-01 to 2007-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[9/26] Fetching data for 2008 (2008-01-01 to 2008-12-31)...\n",
      "   ‚úÖ 8,784 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[10/26] Fetching data for 2009 (2009-01-01 to 2009-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[11/26] Fetching data for 2010 (2010-01-01 to 2010-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[12/26] Fetching data for 2011 (2011-01-01 to 2011-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[13/26] Fetching data for 2012 (2012-01-01 to 2012-12-31)...\n",
      "   ‚úÖ 8,784 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[14/26] Fetching data for 2013 (2013-01-01 to 2013-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[15/26] Fetching data for 2014 (2014-01-01 to 2014-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[16/26] Fetching data for 2015 (2015-01-01 to 2015-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[17/26] Fetching data for 2016 (2016-01-01 to 2016-12-31)...\n",
      "   ‚úÖ 8,784 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[18/26] Fetching data for 2017 (2017-01-01 to 2017-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[19/26] Fetching data for 2018 (2018-01-01 to 2018-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[20/26] Fetching data for 2019 (2019-01-01 to 2019-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[21/26] Fetching data for 2020 (2020-01-01 to 2020-12-31)...\n",
      "   ‚úÖ 8,784 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[22/26] Fetching data for 2021 (2021-01-01 to 2021-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[23/26] Fetching data for 2022 (2022-01-01 to 2022-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[24/26] Fetching data for 2023 (2023-01-01 to 2023-12-31)...\n",
      "   ‚úÖ 8,760 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[25/26] Fetching data for 2024 (2024-01-01 to 2024-12-31)...\n",
      "   ‚úÖ 8,784 records fetched\n",
      "   ‚è≥ Waiting 2s before next request...\n",
      "[26/26] Fetching data for 2025 (2025-01-01 to 2025-12-05)...\n",
      "   ‚úÖ 8,136 records fetched\n",
      "\n",
      "üéâ Data successfully saved to ../data\\historical_data_2000_2024.csv\n",
      "üìä Total records: 227,304\n",
      "   id           timestamp  hour  day  month  year  temp  humidity  windspeed  \\\n",
      "0   0 2000-01-01 00:00:00     0    1      1  2000  21.8        98        4.0   \n",
      "1   1 2000-01-01 01:00:00     1    1      1  2000  21.4        99        4.0   \n",
      "2   2 2000-01-01 02:00:00     2    1      1  2000  21.4        98        3.2   \n",
      "3   3 2000-01-01 03:00:00     3    1      1  2000  21.2        99        4.6   \n",
      "4   4 2000-01-01 04:00:00     4    1      1  2000  21.0        99        3.6   \n",
      "\n",
      "   sealevelpressure  ...  surface_pressure  weather_code  conditions  \\\n",
      "0            1008.4  ...             984.5             3    Overcast   \n",
      "1            1007.9  ...             983.9             3    Overcast   \n",
      "2            1007.4  ...             983.4             3    Overcast   \n",
      "3            1007.0  ...             983.0             3    Overcast   \n",
      "4            1006.9  ...             982.9             3    Overcast   \n",
      "\n",
      "   temp_max_daily  temp_min_daily weather_code_daily  temp_mean_daily  \\\n",
      "0            27.5            20.8                 53             24.1   \n",
      "1            27.5            20.8                 53             24.1   \n",
      "2            27.5            20.8                 53             24.1   \n",
      "3            27.5            20.8                 53             24.1   \n",
      "4            27.5            20.8                 53             24.1   \n",
      "\n",
      "   humidity_avg_daily  pressure_avg_daily  windspeed_avg_daily  \n",
      "0                  91              1007.3                  6.3  \n",
      "1                  91              1007.3                  6.3  \n",
      "2                  91              1007.3                  6.3  \n",
      "3                  91              1007.3                  6.3  \n",
      "4                  91              1007.3                  6.3  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Coordinates and Parameters\n",
    "LATITUDE = -7.0520702239386175\n",
    "LONGITUDE = 110.43532807750137\n",
    "TIMEZONE = \"Asia/Jakarta\"\n",
    "API_URL = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "# Rate Limiting Config\n",
    "MAX_RETRIES = 5\n",
    "BASE_DELAY = 2  # Base delay between requests (seconds)\n",
    "RETRY_DELAY = 30  # Initial retry delay for 429 errors (seconds)\n",
    "\n",
    "# Weather Condition Mapping (Optional helper, main logic uses weather_code)\n",
    "def map_weather_code(code):\n",
    "    \"\"\"Maps WMO weather code to user's custom condition string.\"\"\"\n",
    "    if code is None:\n",
    "        return 'Unknown'\n",
    "    if code == 0:\n",
    "        return 'Clear'\n",
    "    elif code in [1, 2]:\n",
    "        return 'Partially cloudy'\n",
    "    elif code in [3, 45, 48]:\n",
    "        return 'Overcast'\n",
    "    elif code in [51, 53, 55]:\n",
    "        return 'Rain'\n",
    "    elif code in [61, 63, 65]:\n",
    "        return 'Rain, Overcast'\n",
    "    elif code in [80, 81, 82]:\n",
    "        return 'Rain, Partially cloudy'\n",
    "    elif code in [95, 96, 99]:\n",
    "        return 'Rain'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "def fetch_hourly_data_chunk(start_date, end_date, retries=0):\n",
    "    \"\"\"Fetch hourly and daily data for a specific date range with retry logic.\"\"\"\n",
    "    params = {\n",
    "        \"latitude\": LATITUDE,\n",
    "        \"longitude\": LONGITUDE,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"hourly\": [\"temperature_2m\", \"weather_code\", \"relative_humidity_2m\", \n",
    "                   \"pressure_msl\", \"wind_speed_10m\", \"rain\", \"precipitation\", \n",
    "                   \"apparent_temperature\", \"surface_pressure\"],\n",
    "        \"daily\": [\"temperature_2m_max\", \"temperature_2m_min\", \"weather_code\", \n",
    "                  \"temperature_2m_mean\", \"relative_humidity_2m_mean\", \n",
    "                  \"pressure_msl_mean\", \"wind_speed_10m_mean\"],\n",
    "        \"timezone\": TIMEZONE\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(API_URL, params=params)\n",
    "        \n",
    "        # Handle rate limiting (429)\n",
    "        if response.status_code == 429:\n",
    "            if retries < MAX_RETRIES:\n",
    "                wait_time = RETRY_DELAY * (2 ** retries)  # Exponential backoff\n",
    "                print(f\"   ‚ö†Ô∏è Rate limited! Waiting {wait_time}s before retry {retries + 1}/{MAX_RETRIES}...\")\n",
    "                time.sleep(wait_time)\n",
    "                return fetch_hourly_data_chunk(start_date, end_date, retries + 1)\n",
    "            else:\n",
    "                print(f\"   ‚ùå Max retries reached for {start_date} to {end_date}\")\n",
    "                return None\n",
    "        \n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        if retries < MAX_RETRIES:\n",
    "            wait_time = RETRY_DELAY * (2 ** retries)\n",
    "            print(f\"   ‚ö†Ô∏è Error: {e}. Retrying in {wait_time}s...\")\n",
    "            time.sleep(wait_time)\n",
    "            return fetch_hourly_data_chunk(start_date, end_date, retries + 1)\n",
    "        else:\n",
    "            print(f\"   ‚ùå Failed after {MAX_RETRIES} retries: {e}\")\n",
    "            return None\n",
    "\n",
    "def fetch_historical_hourly_data():\n",
    "    \"\"\"Fetch hourly and daily data from 2000 to today in yearly chunks.\"\"\"\n",
    "    # today = datetime.now()\n",
    "    today = datetime(2025, 12, 5) # Set to 2025-12-05 as requested\n",
    "    start_year = 2000\n",
    "    end_year = today.year\n",
    "    \n",
    "    all_data = []\n",
    "    total_years = end_year - start_year + 1\n",
    "    \n",
    "    for idx, year in enumerate(range(start_year, end_year + 1)):\n",
    "        start_date = f\"{year}-01-01\"\n",
    "        if year == end_year:\n",
    "            end_date = today.strftime(\"%Y-%m-%d\")\n",
    "        else:\n",
    "            end_date = f\"{year}-12-31\"\n",
    "        \n",
    "        print(f\"[{idx + 1}/{total_years}] Fetching data for {year} ({start_date} to {end_date})...\")\n",
    "        \n",
    "        data = fetch_hourly_data_chunk(start_date, end_date)\n",
    "        \n",
    "        if data is None:\n",
    "            print(f\"   ‚è≠Ô∏è Skipping year {year} due to errors\")\n",
    "            continue\n",
    "            \n",
    "        hourly_data = data.get(\"hourly\", {})\n",
    "        daily_data = data.get(\"daily\", {})\n",
    "        \n",
    "        if not hourly_data:\n",
    "            print(f\"   ‚ö†Ô∏è No hourly data found for {year}.\")\n",
    "            continue\n",
    "        \n",
    "        # Process hourly data\n",
    "        df_hourly = pd.DataFrame({\n",
    "            \"timestamp\": hourly_data[\"time\"],\n",
    "            \"temp\": hourly_data[\"temperature_2m\"],\n",
    "            \"humidity\": hourly_data[\"relative_humidity_2m\"],\n",
    "            \"windspeed\": hourly_data[\"wind_speed_10m\"],\n",
    "            \"sealevelpressure\": hourly_data[\"pressure_msl\"],\n",
    "            \"weather_code\": hourly_data[\"weather_code\"],\n",
    "            \"rain\": hourly_data[\"rain\"],\n",
    "            \"precipitation\": hourly_data[\"precipitation\"],\n",
    "            \"apparent_temperature\": hourly_data[\"apparent_temperature\"],\n",
    "            \"surface_pressure\": hourly_data[\"surface_pressure\"]\n",
    "        })\n",
    "        df_hourly[\"timestamp\"] = pd.to_datetime(df_hourly[\"timestamp\"])\n",
    "        df_hourly[\"date_only\"] = df_hourly[\"timestamp\"].dt.date # Helper for merging\n",
    "\n",
    "        # Process daily data (with new avg features)\n",
    "        df_daily = pd.DataFrame({\n",
    "            \"date_only\": daily_data[\"time\"],\n",
    "            \"temp_max_daily\": daily_data[\"temperature_2m_max\"],\n",
    "            \"temp_min_daily\": daily_data[\"temperature_2m_min\"],\n",
    "            \"weather_code_daily\": daily_data[\"weather_code\"],\n",
    "            \"temp_mean_daily\": daily_data[\"temperature_2m_mean\"],\n",
    "            \"humidity_avg_daily\": daily_data[\"relative_humidity_2m_mean\"],\n",
    "            \"pressure_avg_daily\": daily_data[\"pressure_msl_mean\"],\n",
    "            \"windspeed_avg_daily\": daily_data[\"wind_speed_10m_mean\"]\n",
    "        })\n",
    "        df_daily[\"date_only\"] = pd.to_datetime(df_daily[\"date_only\"]).dt.date\n",
    "\n",
    "        # Merge hourly and daily data\n",
    "        df_year = pd.merge(df_hourly, df_daily, on=\"date_only\", how=\"left\")\n",
    "        df_year = df_year.drop(columns=[\"date_only\"]) # Drop helper column\n",
    "        \n",
    "        all_data.append(df_year)\n",
    "        print(f\"   ‚úÖ {len(df_year):,} records fetched\")\n",
    "        \n",
    "        # Longer delay between requests to avoid rate limiting\n",
    "        if idx < total_years - 1:  # Don't wait after last request\n",
    "            print(f\"   ‚è≥ Waiting {BASE_DELAY}s before next request...\")\n",
    "            time.sleep(BASE_DELAY)\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"‚ùå No data fetched.\")\n",
    "        return\n",
    "    \n",
    "    df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"day\"] = df[\"timestamp\"].dt.day\n",
    "    df[\"month\"] = df[\"timestamp\"].dt.month\n",
    "    df[\"year\"] = df[\"timestamp\"].dt.year\n",
    "    \n",
    "    df[\"conditions\"] = df[\"weather_code\"].apply(map_weather_code)\n",
    "    df[\"id\"] = range(len(df))\n",
    "    \n",
    "    output_columns = [\"id\", \"timestamp\", \"hour\", \"day\", \"month\", \"year\", \n",
    "                      \"temp\", \"humidity\", \"windspeed\", \"sealevelpressure\", \n",
    "                      \"rain\", \"precipitation\", \"apparent_temperature\", \"surface_pressure\",\n",
    "                      \"weather_code\", \"conditions\", \n",
    "                      \"temp_max_daily\", \"temp_min_daily\", \"weather_code_daily\", \"temp_mean_daily\",\n",
    "                      \"humidity_avg_daily\", \"pressure_avg_daily\", \"windspeed_avg_daily\"]\n",
    "    \n",
    "    final_df = df[output_columns]\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    output_dir = \"../data\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    output_file = os.path.join(output_dir, \"historical_data_2000_2024.csv\")\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nüéâ Data successfully saved to {output_file}\")\n",
    "    print(f\"üìä Total records: {len(final_df):,}\")\n",
    "    print(final_df.head())\n",
    "\n",
    "fetch_historical_hourly_data()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
