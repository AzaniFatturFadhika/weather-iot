{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Model Training Notebook\n",
    "\n",
    "This notebook implements the training pipeline for weather prediction models based on the methodology described in the project documentation.\n",
    "\n",
    "## 1. Environment Setup and Library Loading\n",
    "\n",
    "**Goal:** Import necessary libraries for data processing, model training, evaluation, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection and Loading\n",
    "\n",
    "**Goal:** Load the historical dataset.\n",
    "**Source:** `../../data_collections/datasets/historical_data_hourly.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = '../../data_collections/datasets/historical_data_hourly.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows and info\n",
    "print(f\"Total records: {len(df)}\")\n",
    "display(df.head())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "**Goal:** Clean, standardize, and prepare data for regression training.\n",
    "**Steps:**\n",
    "- Select features\n",
    "- Format date/time\n",
    "- Label Encode categorical variables (weather condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct timestamp from year, month, day, hour columns\n",
    "if {'year', 'month', 'day', 'hour'}.issubset(df.columns):\n",
    "    df['timestamp'] = pd.to_datetime(df[['year', 'month', 'day', 'hour']])\n",
    "elif 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Handle missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Rename columns to match the notebook's expected names\n",
    "column_mapping = {\n",
    "    'temp': 'temperature',\n",
    "    'windspeed': 'wind_speed',\n",
    "    'sealevelpressure': 'pressure'\n",
    "}\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Label Encoding for 'conditions'\n",
    "le = LabelEncoder()\n",
    "\n",
    "if 'conditions' in df.columns and df['conditions'].dtype == 'object':\n",
    "    df['condition_encoded'] = le.fit_transform(df['conditions'])\n",
    "    print(\"Encoded 'conditions' to 'condition_encoded'\")\n",
    "\n",
    "print(\"Data preprocessing complete. Columns:\", df.columns.tolist())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Comparison\n",
    "\n",
    "**Goal:** Train and compare four regression models.\n",
    "**Models:** Linear Regression, Decision Tree, KNN, Random Forest.\n",
    "**Target:** We will test predicting **Temperature** as a primary example for comparison, or average performance across targets.\n",
    "**Overfitting Prevention:** Added Cross-Validation to ensure model stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Features (X) and Target (y)\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "df['day'] = df['timestamp'].dt.day\n",
    "\n",
    "X = df[['hour', 'month', 'day']]\n",
    "if 'condition_encoded' in df.columns:\n",
    "    X = df[['hour', 'month', 'day', 'condition_encoded']]\n",
    "\n",
    "# Target: Temperature (as representative for model comparison)\n",
    "y_temp = df['temperature']\n",
    "\n",
    "def evaluate_models(X, y, test_size=0.2, random_state=42):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    models = {\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": DecisionTreeRegressor(random_state=random_state),\n",
    "        \"KNN\": KNeighborsRegressor(),\n",
    "        \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-Validation (5-fold)\n",
    "        cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "        cv_mean = cv_scores.mean()\n",
    "        cv_std = cv_scores.std()\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"MSE\": mse,\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R2 Score\": r2,\n",
    "            \"CV R2 Mean\": cv_mean,\n",
    "            \"CV R2 Std\": cv_std\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Comparing models for Temperature prediction (with Cross-Validation)...\")\n",
    "comparison_results = evaluate_models(X, y_temp)\n",
    "display(comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis of Results and Individual Parameter Performance\n",
    "\n",
    "**Goal:** Evaluate the best model (Random Forest) on all individual parameters: Temperature, Humidity, Wind Speed, Pressure.\n",
    "**Overfitting Prevention:** \n",
    "- Compare Training R2 vs Testing R2.\n",
    "- Use Hyperparameter Tuning (GridSearchCV) to find optimal settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['temperature', 'humidity', 'wind_speed', 'pressure']\n",
    "rf_results = []\n",
    "best_models = {}\n",
    "\n",
    "# Hyperparameter Grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "for target in targets:\n",
    "    print(f\"\\nOptimizing model for {target}...\")\n",
    "    y = df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Base model\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    \n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_rf = grid_search.best_estimator_\n",
    "    print(f\"Best Parameters for {target}: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Save model for later\n",
    "    best_models[target] = best_rf\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_test = best_rf.predict(X_test)\n",
    "    y_pred_train = best_rf.predict(X_train)\n",
    "    \n",
    "    # Metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    \n",
    "    # Check for overfitting\n",
    "    overfitting_gap = r2_train - r2_test\n",
    "    status = \"Good\" if overfitting_gap < 0.1 else \"Potential Overfitting\"\n",
    "    \n",
    "    rf_results.append({\n",
    "        \"Parameter\": target.capitalize(),\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"Test R2\": r2_test,\n",
    "        \"Train R2\": r2_train,\n",
    "        \"Gap\": overfitting_gap,\n",
    "        \"Status\": status\n",
    "    })\n",
    "\n",
    "rf_results_df = pd.DataFrame(rf_results)\n",
    "display(rf_results_df)\n",
    "\n",
    "# Visualizing Performance\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Parameter', y='Test R2', data=rf_results_df, palette='viridis')\n",
    "plt.title('Optimized Random Forest Performance (Test R2 Score)')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving the Best Model\n",
    "\n",
    "**Goal:** Save the trained Random Forest models for backend use into a **single file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_dir = '../models'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save all models in a single dictionary\n",
    "filename = f\"{save_dir}/weather_prediction_models.pkl\"\n",
    "joblib.dump(best_models, filename)\n",
    "\n",
    "print(f\"Saved all models to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization: Actual vs. Predicted\n",
    "\n",
    "**Goal:** Visualize prediction accuracy for January 2020 (Daily Aggregation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for January 2020\n",
    "jan_2020 = df[(df['timestamp'].dt.year == 2020) & (df['timestamp'].dt.month == 1)].copy()\n",
    "\n",
    "if len(jan_2020) == 0:\n",
    "    print(\"No data found for Jan 2020. Using first month of available data for visualization.\")\n",
    "    # Fallback to first month in data\n",
    "    first_date = df['timestamp'].min()\n",
    "    jan_2020 = df[(df['timestamp'].dt.year == first_date.year) & (df['timestamp'].dt.month == first_date.month)].copy()\n",
    "\n",
    "# Aggregate daily\n",
    "daily_data = jan_2020.resample('D', on='timestamp').mean().dropna()\n",
    "\n",
    "# Prepare X for daily data (needs same features as training)\n",
    "daily_data['hour'] = 12 # Assume mid-day for daily avg prediction or just use features available\n",
    "daily_data['month'] = daily_data.index.month\n",
    "daily_data['day'] = daily_data.index.day\n",
    "# Note: 'condition_encoded' might need mode aggregation, but mean is used here for simplicity or re-encoding\n",
    "if 'condition_encoded' in daily_data.columns:\n",
    "    daily_data['condition_encoded'] = daily_data['condition_encoded'].round().astype(int)\n",
    "\n",
    "X_daily = daily_data[['hour', 'month', 'day']]\n",
    "if 'condition_encoded' in df.columns:\n",
    "    X_daily = daily_data[['hour', 'month', 'day', 'condition_encoded']]\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 20))\n",
    "\n",
    "for i, target in enumerate(targets):\n",
    "    # Predict using the saved best model\n",
    "    model = best_models[target]\n",
    "    y_pred_daily = model.predict(X_daily)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.plot(daily_data.index, daily_data[target], label='Actual', color='blue', marker='o')\n",
    "    ax.plot(daily_data.index, y_pred_daily, label='Predicted', color='red', linestyle='--', marker='x')\n",
    "    \n",
    "    ax.set_title(f'Actual vs Predicted {target.capitalize()} (Jan 2020)')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(target.capitalize())\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization: Incremental Data Impact\n",
    "\n",
    "**Goal:** Show how R2 score improves with more data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fractions = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "r2_scores = []\n",
    "\n",
    "# Target for this test: Temperature\n",
    "y = df['temperature']\n",
    "\n",
    "for frac in data_fractions:\n",
    "    # Sample fraction of data\n",
    "    subset = df.sample(frac=frac, random_state=42)\n",
    "    X_sub = subset[['hour', 'month', 'day']]\n",
    "    if 'condition_encoded' in df.columns:\n",
    "        X_sub = subset[['hour', 'month', 'day', 'condition_encoded']]\n",
    "    y_sub = subset['temperature']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sub, y_sub, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Use a simpler model or best params from before\n",
    "    rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    r2_scores.append(r2_score(y_test, y_pred))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_fractions, r2_scores, marker='o', color='green')\n",
    "plt.title('Impact of Incremental Data on Model Performance (Temperature)')\n",
    "plt.xlabel('Fraction of Data Used')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
